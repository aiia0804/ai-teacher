import streamlit as st
from streamlit_mic_recorder import mic_recorder
import requests
import json
import base64
import time
import io
import tempfile
import os
from typing import Dict, List, Optional, Any
import uuid
import sounddevice as sd
import soundfile as sf
import numpy as np
from pydub import AudioSegment
from pydub.playback import play
import queue
import wave
from PIL import Image
import streamlit.components.v1 as components
import threading
import asyncio
import requests

# é…ç½® Streamlit é é¢
st.set_page_config(
    page_title="è‹±èªå°è©±AIæ•™å¸«",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å…¨å±€è®Šæ•¸
API_URL = "http://localhost:8000"  # API æœå‹™å™¨URL
SAMPLE_RATE = 16000  # éŒ„éŸ³æ¡æ¨£ç‡
DURATION = 10  # éŒ„éŸ³æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰
MAX_TRANSCRIPT_LENGTH = 100  # é¡¯ç¤ºçš„æœ€å¤§è½‰éŒ„æ–‡æœ¬é•·åº¦

def init_session_state():
    # åˆå§‹åŒ–å°è©±æ­·å²
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    
    # åˆå§‹åŒ–éŒ„éŸ³ç‹€æ…‹
    if "is_recording" not in st.session_state:
        st.session_state["is_recording"] = False
    
    # åˆå§‹åŒ–éŸ³é »æ’­æ”¾åˆ—è¡¨
    if "audio_to_play" not in st.session_state:
        st.session_state["audio_to_play"] = []
        
    # åˆå§‹åŒ–éŸ³é »æ’­æ”¾æ¨™è¨˜
    if "audio_bytes_to_play" not in st.session_state:
        st.session_state["audio_bytes_to_play"] = None
        
    # åˆå§‹åŒ–éŸ³é »æ’­æ”¾è¨ˆæ•¸å™¨ï¼ˆç”¨æ–¼å¼·åˆ¶é‡æ–°æ¸²æŸ“ï¼‰
    if "audio_play_counter" not in st.session_state:
        st.session_state["audio_play_counter"] = 0
        
    # åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
    if "conversation_id" not in st.session_state:
        st.session_state["conversation_id"] = str(uuid.uuid4())
    if "audio_bytes" not in st.session_state:
        st.session_state["audio_bytes"] = None
    if "transcript" not in st.session_state:
        st.session_state["transcript"] = ""
    if "realtime_response" not in st.session_state:
        st.session_state["realtime_response"] = ""
    if "processed_audio" not in st.session_state:
        st.session_state["processed_audio"] = False
    if "play_requested" not in st.session_state:
        st.session_state["play_requested"] = False
    if "audio_stream_active" not in st.session_state:
        st.session_state["audio_stream_active"] = False
    if "recorder_key_counter" not in st.session_state:
        st.session_state["recorder_key_counter"] = 0
    if "audio_permission_granted" not in st.session_state:
        st.session_state["audio_permission_granted"] = False

init_session_state()

audio_files_list = []

def get_theme_specific_css():
    theme = "lights"
    # æ ¹æ“šä¸»é¡Œè¿”å›å°æ‡‰çš„ CSS
    if theme == "light":
        return """
        <style>
            color: #262730 !important;
            /* äº®è‰²æ¨¡å¼ä¸‹çš„å­—é«”é¡è‰² */
            .main-header { color: #4169E1 !important; }
            .chat-message {padding: 1.5rem; border-radius: 0.5rem; margin-bottom: 1rem; display: flex;}
            .chat-message.user { background-color: #f0f2f6; color: #262730;}
            .chat-message.bot {background-color: #e6f3ff; color: #262730;}
            .feedback-box { background-color: #f0f2f6; }
            .stSelectbox label, .stSelectbox div[data-baseweb="select"] {
            }
            div[data-baseweb="popover"] {
                background-color: #ffffff !important;
            }
        </style>
        """
    else:  # dark mode
        return """
        <style>
            /* æš—è‰²æ¨¡å¼ä¸‹çš„å­—é«”é¡è‰² */
            color: #FAFAFA !important;
            .main-header { color: #4D9FF5 !important; }
            .chat-message {padding: 1.5rem; border-radius: 0.5rem; margin-bottom: 1rem; display: flex;}
            .chat-message.user { background-color: #2D2D2D; color: #FAFAFA;}
            .chat-message.bot { background-color: #22252A; color: #FAFAFA;}
            .feedback-box { background-color: #2D2D2D; }
            .stSelectbox label, .stSelectbox div[data-baseweb="select"] {
            }
            div[data-baseweb="popover"] {
                background-color: #333333 !important;
            }
        </style>
        """

def autoplay_audio(audio_file):
    """
    è‡ªå‹•æ’­æ”¾éŸ³é »æ–‡ä»¶ - ä½¿ç”¨Streamlitçš„éŸ³é »æ’­æ”¾å™¨
    
    Args:
        audio_file: éŸ³é »æ–‡ä»¶è·¯å¾‘æˆ–éŸ³é »å­—ç¯€æ•¸æ“š
    """
    try:
        print(f"å˜—è©¦æ’­æ”¾éŸ³é »æ–‡ä»¶: {audio_file}")
        
        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾‘ï¼Œå‰‡è®€å–æ–‡ä»¶å…§å®¹
        if isinstance(audio_file, str) and os.path.exists(audio_file):
            with open(audio_file, "rb") as f:
                audio_bytes = f.read()
        else:
            # å‡è¨­å·²ç¶“æ˜¯å­—ç¯€æ•¸æ“š
            audio_bytes = audio_file
            
        # ä½¿ç”¨base64ç·¨ç¢¼ä¸¦å‰µå»ºå¸¶æœ‰autoplayå±¬æ€§çš„audioæ¨™ç±¤
        audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_html = f"""
        <audio controls autoplay="true">
          <source src="data:audio/wav;base64,{audio_b64}" type="audio/wav">
          æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æŒéŸ³é »æ’­æ”¾ã€‚
        </audio>
        """
        return audio_html
        
    except Exception as e:
        print(f"æ’­æ”¾éŸ³é »éŒ¯èª¤: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None

# å°‡éŸ³é »æ–‡ä»¶æ·»åŠ åˆ°æ’­æ”¾ä½‡åˆ—
# é€™å€‹å‡½æ•¸å¯ä»¥åœ¨ä»»ä½•ç·šç¨‹ä¸­èª¿ç”¨
# ä½†åªæœƒå°‡éŸ³é »è·¯å¾‘æ·»åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œä¸æœƒç›´æ¥æ’­æ”¾
# å¯¦éš›æ’­æ”¾æœƒåœ¨ä¸»ç·šç¨‹ä¸­é€²è¡Œ

# å…¨å±€éŸ³é »æ’­æ”¾åˆ—è¡¨
# å­˜å„²éœ€è¦æ’­æ”¾çš„éŸ³é »æ–‡ä»¶è·¯å¾‘
# ä¸»ç·šç¨‹æœƒå®šæœŸæª¢æŸ¥é€™å€‹åˆ—è¡¨ä¸¦æ’­æ”¾æ–°çš„éŸ³é »
# é€™æ¨£å¯ä»¥é¿å…åœ¨å¾Œå°ç·šç¨‹ä¸­èª¿ç”¨Streamlitå‡½æ•¸

if "audio_to_play" not in st.session_state:
    st.session_state["audio_to_play"] = []

def speech_to_text(audio_bytes: bytes) -> Optional[str]:
    """
    å°‡éŸ³é »è½‰æ›ç‚ºæ–‡æœ¬
    
    Args:
        audio_bytes: éŸ³é »æ•¸æ“šçš„äºŒé€²åˆ¶å…§å®¹
        
    Returns:
        è½‰éŒ„æ–‡æœ¬
    """
    try:
        #print(audio_bytes)
        # æª¢æŸ¥éŸ³é »æ•¸æ“š
        if not audio_bytes:
            st.error("ç„¡æ•ˆçš„éŸ³é »æ•¸æ“š")
            return None

        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        payload = {
            "audio_base64": audio_base64,
            "language": "en"
        }
        
        # ç™¼é€è«‹æ±‚

        response = requests.post(f"{API_URL}/api/stt", json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        if result.get("success", False):
            transcribed_text = result.get("text", "")
            if not transcribed_text:
                st.warning("æœªèƒ½è­˜åˆ¥ä»»ä½•èªéŸ³ï¼Œè«‹é‡æ–°å˜—è©¦")
                return None
            return transcribed_text
        else:
            st.error("è½‰éŒ„å¤±æ•—")
            return None
    
    except Exception as e:
        st.error(f"èªéŸ³è½‰æ–‡æœ¬éŒ¯èª¤: {str(e)}")
        return None

def chat_with_llm(message: str) -> str:
    """
    èˆ‡LLMæ¨¡å‹é€²è¡Œå°è©± - APIç«¯é»å·²ç¶“è™•ç†äº†TTSï¼Œä¸¦æ”¯æŒSSEä¾†ç²å–å¯¦æ™‚å›æ‡‰
    
    Args:
        message: ç”¨æˆ¶æ¶ˆæ¯
        
    Returns:
        æ¨¡å‹å›æ‡‰
    """
    try:
        # åœæ­¢ä»»ä½•æ­£åœ¨é€²è¡Œçš„éŸ³é »æµ
        stop_tts_stream()
        
        # ç­‰å¾…ä¸€ä¸‹ç¢ºä¿éŸ³é »æµå·²ç¶“åœæ­¢
        time.sleep(0.5)
        
        # å•Ÿå‹•æ–°çš„TTSæµå¼æ¥æ”¶
        start_tts_stream()
        
        # æº–å‚™è«‹æ±‚æ•¸æ“š
        payload = {
            "message": message,
            "conversation_id": st.session_state["conversation_id"],
            "context": st.session_state["messages"],
            "scenario": "general"
        }
        
        print(f"ç™¼é€è«‹æ±‚åˆ°LLM API: {message[:30]}...")
        
        # ä½¿ç”¨æ¨™æº–APIè€Œä¸æ˜¯æµå¼ç”Ÿæˆ
        response = requests.post(f"{API_URL}/api/llm", json=payload)
        response.raise_for_status()
        result = response.json()
        
        print(f"æ”¶åˆ°LLMå›æ‡‰ï¼Œé•·åº¦: {len(result.get('response', ''))} å­—ç¬¦")
        
        # ç­‰å¾…ä¸€æ®µæ™‚é–“è®“éŸ³é »æµé–‹å§‹
        time.sleep(1.0)
        
        return result.get("response", "")
        
        # ä½¿ç”¨SSEç²å–å¯¦æ™‚å›æ‡‰
        with requests.post(
            f"{API_URL}/api/stream_llm",
            json=payload,
            stream=True,
            headers={"Accept": "text/event-stream"}
        ) as response:
            response.raise_for_status()
            
            # é‡ç½®å¯¦æ™‚å›æ‡‰
            st.session_state["realtime_response"] = ""
            full_response = ""
            
            # è™•ç†SSEäº‹ä»¶
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data:'):
                        # æå–æ•¸æ“š
                        data = line[5:].strip()
                        if data == "[DONE]":
                            break
                            
                        try:
                            # è§£æJSONæ•¸æ“š
                            event_data = json.loads(data)
                            if 'text' in event_data:
                                # æ›´æ–°å¯¦æ™‚å›æ‡‰
                                text_chunk = event_data['text']
                                full_response += text_chunk
                                st.session_state["realtime_response"] = full_response
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥æ·»åŠ 
                            full_response += data
                            st.session_state["realtime_response"] = full_response
            
            # è¿”å›å®Œæ•´å›æ‡‰
            return full_response
    
    except Exception as e:
        st.error(f"å°è©±éŒ¯èª¤: {str(e)}")
        return f"æŠ±æ­‰ï¼Œå‡ºç¾äº†éŒ¯èª¤: {str(e)}"

def text_to_speech(text: str) -> Optional[bytes]:
    """
    å°‡æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³
    
    Args:
        text: è¦è½‰æ›çš„æ–‡æœ¬
        
    Returns:
        éŸ³é »æ•¸æ“šçš„äºŒé€²åˆ¶å…§å®¹
    """
    try:
        # æº–å‚™è«‹æ±‚æ•¸æ“š
        payload = {
            "text": text,
            "voice": "af_heart.pt",
            "speed": 1.0
        }
        
        # ç™¼é€è«‹æ±‚
        response = requests.post(f"{API_URL}/api/tts", json=payload)
        response.raise_for_status()
        
        # è¿”å›éŸ³é »æ•¸æ“š
        return response.content
    
    except Exception as e:
        st.error(f"æ–‡æœ¬è½‰èªéŸ³éŒ¯èª¤: {str(e)}")
        return None

# å‰µå»ºå…¨å±€è®Šé‡ä»¥åœ¨ç·šç¨‹ä¹‹é–“å…±äº«ç‹€æ…‹
is_connected_to_tts = False  # TTSæµé€£æ¥ç‹€æ…‹
is_playing = False  # éŸ³é »æ’­æ”¾ç‹€æ…‹
stop_event = threading.Event()  # åœæ­¢äº‹ä»¶
audio_stream_threads = []  # éŸ³é »æµç·šç¨‹
audio_queue = queue.Queue()  # éŸ³é »éšŠåˆ—

def start_tts_stream():
    """
    å•Ÿå‹•TTSæµå¼å‚³è¼¸
    """
    global audio_queue, is_connected_to_tts, is_playing, stop_event, audio_stream_threads
    
    # åœæ­¢ä»»ä½•ç¾æœ‰çš„éŸ³é »æµ
    stop_tts_stream()
    
    # é‡ç½®ç‹€æ…‹
    stop_event.clear()
    audio_queue = queue.Queue()
    
    # å•Ÿå‹•æ¥æ”¶ç·šç¨‹
    receive_thread = threading.Thread(target=handle_tts_stream)
    receive_thread.daemon = True
    receive_thread.start()
    audio_stream_threads.append(receive_thread)
    
    # å•Ÿå‹•æ’­æ”¾ç·šç¨‹
    play_thread = threading.Thread(target=audio_player)
    play_thread.daemon = True
    play_thread.start()
    audio_stream_threads.append(play_thread)
    
    print("éŸ³é »æµå·²å•Ÿå‹•")

def stop_tts_stream():
    """
    åœæ­¢TTSæµå¼æ¥æ”¶
    """
    global is_connected_to_tts, stop_event, audio_stream_threads, audio_queue
    
    # è¨­ç½®åœæ­¢æ¨™è¨˜
    stop_event.set()
    is_connected_to_tts = False
    st.session_state["audio_stream_active"] = False
    
    # åœæ­¢æ­£åœ¨æ’­æ”¾çš„éŸ³é »
    try:
        sd.stop()
    except:
        pass
    
    # æ¸…ç©ºéŸ³é »éšŠåˆ—
    try:
        while not audio_queue.empty():
            audio_queue.get_nowait()
    except Exception:
        pass
    
    # ç­‰å¾…ç·šç¨‹çµæŸ
    for thread in audio_stream_threads:
        if thread.is_alive():
            thread.join(timeout=0.5)
    
    # æ¸…ç©ºç·šç¨‹åˆ—è¡¨
    audio_stream_threads.clear()

def handle_tts_stream():
    """è™•ç†TTSæµå¼å‚³è¼¸"""
    global audio_queue, is_connected_to_tts
    
    print("é–‹å§‹æ¥æ”¶TTSæµ")
    is_connected_to_tts = True
    
    # è¨­ç½®é‡è©¦åƒæ•¸
    max_retries = 3
    retry_count = 0
    retry_delay = 1  # åˆå§‹é‡è©¦å»¶é²ï¼ˆç§’ï¼‰
    
    while retry_count < max_retries:
        try:
            # å‰µå»ºä¸€å€‹æ–°çš„æœƒè©±ä»¥è¿½è¹¤æµæ•¸æ“š
            import requests
            import json
            
            # é–‹å§‹æµå¼è¦æ±‚
            url = "http://localhost:8000/api/tts-stream"
            headers = {"Accept": "text/event-stream"}
            
            # ä½¿ç”¨è¦æ±‚åº«çš„æµå¼åŠŸèƒ½
            response = requests.get(url, headers=headers, stream=True)
            
            # ç¢ºä¿é€£æ¥æˆåŠŸ
            if response.status_code != 200:
                print(f"é€£æ¥åˆ°TTSæµå¤±æ•—: HTTP {response.status_code}")
                retry_count += 1
                time.sleep(retry_delay)
                retry_delay *= 2  # æŒ‡æ•¸å»¶é²å¢åŠ 
                continue
            
            # é‡ç½®é‡è©¦è¨ˆæ•¸å™¨
            retry_count = 0
            
            # è¨ˆç®—æ”¶åˆ°çš„ç‰‡æ®µæ•¸
            chunk_count = 0
            
            # æ‰‹å‹•è§£æSSEæµ
            buffer = ""
            
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    # å°‡äºŒé€²åˆ¶è½‰æ›ç‚ºæ–‡æœ¬
                    buffer += chunk.decode('utf-8')
                    
                    # å°‹æ‰¾å®Œæ•´çš„SSEäº‹ä»¶
                    while "\n\n" in buffer:
                        event, buffer = buffer.split("\n\n", 1)
                        lines = event.split("\n")
                        
                        event_type = None
                        data = None
                        
                        for line in lines:
                            if line.startswith("event: "):
                                event_type = line[7:]
                            elif line.startswith("data: "):
                                data = line[6:]
                        
                        if event_type == "audio" and data:
                            try:
                                # è§£æJSONæ•¸æ“š
                                json_data = json.loads(data)
                                audio_base64 = json_data.get("audio")
                                
                                if audio_base64:
                                    # å°‡éŸ³é »æ•¸æ“šæ”¾å…¥éšŠåˆ—
                                    audio_queue.put(audio_base64)
                                    chunk_count += 1
                                    print(f"æ¥æ”¶åˆ°éŸ³é »æ•¸æ“š: {len(audio_base64)} å­—ç¯€ (ç¸½è¨ˆ: {chunk_count} å€‹ç‰‡æ®µ)")
                            except json.JSONDecodeError as e:
                                print(f"JSONè§£æéŒ¯èª¤: {str(e)}")
                            except Exception as e:
                                print(f"è™•ç†éŸ³é »æ•¸æ“šå‡ºéŒ¯: {str(e)}")
                                import traceback
                                print(traceback.format_exc())
                        
                        elif event_type == "close":
                            print("æœå‹™å™¨å·²é—œé–‰TTSæµé€£æ¥")
                            break
            
            # å¦‚æœåˆ°é”é€™è£¡ï¼Œè¡¨ç¤ºé€£æ¥å·²çµæŸï¼Œä½†æ²’æœ‰éŒ¯èª¤
            break
        
        except requests.exceptions.ConnectionError as e:
            print(f"TTSæµé€£æ¥éŒ¯èª¤: {str(e)}")
            retry_count += 1
            print(f"å˜—è©¦é‡æ–°é€£æ¥ ({retry_count}/{max_retries})")
            time.sleep(retry_delay)
            retry_delay *= 2  # æŒ‡æ•¸å»¶é²å¢åŠ 
        
        except Exception as e:
            print(f"TTSæµè™•ç†å‡ºéŒ¯: {str(e)}")
            import traceback
            print(traceback.format_exc())
            break
    
    is_connected_to_tts = False
    print("çµæŸæ¥æ”¶TTSæµ")

# å‰µå»ºä¸€å€‹ç›®éŒ„ä¾†å­˜å„²éŸ³é »æ–‡ä»¶
# ä½¿ç”¨ç›¸å°æ–¼æ‡‰ç”¨ç¨‹åºçš„ç›®éŒ„ï¼Œè€Œä¸æ˜¯è‡¨æ™‚ç›®éŒ„
# é€™æ¨£æˆ‘å€‘å¯ä»¥é€šéç¶²çµ¡æœå‹™å™¨æä¾›æª”æ¡ˆ
# å®šç¾©éŸ³é »æ–‡ä»¶ç›®éŒ„
AUDIO_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "static", "audio")

# ç¢ºä¿éŸ³é »ç›®éŒ„å­˜åœ¨
def ensure_audio_directory():
    """ç¢ºä¿éŸ³é »ç›®éŒ„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»ºå®ƒ"""
    if not os.path.exists(AUDIO_DIR):
        os.makedirs(AUDIO_DIR, exist_ok=True)
        print(f"Created audio directory: {AUDIO_DIR}")
    return AUDIO_DIR

# æƒæéŸ³é »æ–‡ä»¶
def scan_audio_files():
    """æƒæéŸ³é »ç›®éŒ„ä¸­çš„æ‰€æœ‰éŸ³é »æ–‡ä»¶ä¸¦æ›´æ–°åˆ—è¡¨"""
    global audio_files_list
    
    # ç¢ºä¿éŸ³é »ç›®éŒ„å­˜åœ¨
    audio_dir = ensure_audio_directory()
    
    # å¦‚æœåˆ—è¡¨ç‚ºç©ºï¼Œå‰‡æƒæç›®éŒ„
    if not audio_files_list:
        # å¾éŸ³é »ç›®éŒ„ä¸­è®€å–æ‰€æœ‰WAVæ–‡ä»¶
        if os.path.exists(audio_dir):
            wav_files = [f for f in os.listdir(audio_dir) if f.endswith('.wav')]
            print(f"Found {len(wav_files)} WAV files in {audio_dir}")
            
            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºæ–‡ä»¶ï¼Œæœ€æ–°çš„åœ¨å‰é¢
            wav_files.sort(key=lambda f: os.path.getmtime(os.path.join(audio_dir, f)), reverse=True)
            
            # å°‡æ–‡ä»¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            for wav_file in wav_files:
                file_path = os.path.join(audio_dir, wav_file)
                # ç¢ºä¿æ–‡ä»¶å­˜åœ¨ä¸”å¤§å°å¤§æ–¼0
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    audio_files_list.append({
                        'path': file_path,
                        'url': f'/static/audio/{wav_file}',
                        'timestamp': os.path.getmtime(file_path),
                        'format': 'audio/wav'
                    })
    
    return audio_files_list

# åˆå§‹åŒ–éŸ³é »æ–‡ä»¶åˆ—è¡¨
audio_files_list = scan_audio_files()

def audio_player():
    """éŸ³é »æ’­æ”¾ç·šç¨‹ - å°‡éŸ³é »æ•¸æ“šå­˜å„²ç‚ºæ–‡ä»¶ä¾›ç¶²é æ’­æ”¾"""
    global is_playing, audio_queue, stop_event, is_connected_to_tts, audio_files_list
    
    # å°å…¥å¿…è¦çš„åº«
    import numpy as np
    import base64
    import io
    import time
    import wave
    
    print("éŸ³é »æ’­æ”¾ç·šç¨‹å·²å•Ÿå‹• - å°‡éŸ³é »å­˜å„²ç‚ºæ–‡ä»¶ä¾›ç¶²é æ’­æ”¾")
    
    # è¨­ç½®éŸ³é »åƒæ•¸
    sample_rate = 24000  # é è¨­é‡‡æ¨£ç‡
    
    # è¨­ç½®ç©ºéšŠåˆ—è¨ˆæ•¸å™¨
    empty_count = 0
    max_empty_count = 50  # æœ€å¤šç­‰å¾…50æ¬¡ç©ºéšŠåˆ—
    
    try:
        while not stop_event.is_set():
            if not audio_queue.empty():
                # å¾éšŠåˆ—ä¸­å–å‡ºéŸ³é »æ•¸æ“š
                audio_data = audio_queue.get()
                
                # é‡ç½®ç©ºéšŠåˆ—è¨ˆæ•¸å™¨
                empty_count = 0
                
                try:
                    # è§£ç¢¼éŸ³é »æ•¸æ“š
                    audio_bytes = base64.b64decode(audio_data)
                    
                    print(f"æº–å‚™è™•ç†éŸ³é »: {len(audio_bytes)} å­—ç¯€")
                    
                    # ç›´æ¥å°‡å­—ç¯€è½‰æ›ç‚º NumPy æ•¸çµ„
                    audio_np = np.frombuffer(audio_bytes, dtype=np.float32)
                    
                    # ç¢ºä¿æ•¸çµ„ä¸ç‚ºç©º
                    if len(audio_np) > 0:
                        # ç›´æ¥ä½¿ç”¨WAVæ ¼å¼ï¼Œé¿å…è½‰æ›å•é¡Œ
                        audio_filename = f"audio_{int(time.time())}_{uuid.uuid4().hex[:8]}.wav"
                        audio_path = os.path.join(AUDIO_DIR, audio_filename)
                        
                        # å°‡NumPyæ•¸çµ„è½‰æ›ç‚ºWAVæ ¼å¼ä¸¦å­˜å„²ç‚ºæ–‡ä»¶
                        with wave.open(audio_path, 'wb') as wav_file:
                            wav_file.setnchannels(1)  # å–®è²é“
                            wav_file.setsampwidth(4)  # 32ä½/8 = 4å­—ç¯€
                            wav_file.setframerate(sample_rate)
                            
                            # å°‡float32è½‰æ›ç‚ºint32
                            # å…ˆå°‡ç¯„åœå¾[-1, 1]ç¸®æ”¾åˆ°[-2^31, 2^31-1]
                            scaled = np.int32(audio_np * 2147483647)
                            wav_file.writeframes(scaled.tobytes())
                        
                        # æ›´æ–°å…¨å±€éŸ³é »æ–‡ä»¶è·¯å¾‘
                        is_playing = True
                        print(f"å·²è™•ç†éŸ³é »ä¸¦å­˜å„²ç‚ºWAVæ–‡ä»¶: {audio_path}")
                        
                        # å°‡éŸ³é »æ–‡ä»¶è·¯å¾‘æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨ä¸­
                        # ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼Œæ–¹ä¾¿å¾ŒçºŒé€šéç¶²çµ¡è¨ªå•
                        relative_path = f"/static/audio/{audio_filename}"
                        
                        # æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨
                        audio_files_list.append({
                            'path': audio_path,
                            'url': relative_path,
                            'timestamp': time.time(),
                            'format': 'audio/wav'
                        })
                        
                        # å°‡éŸ³é »æ–‡ä»¶è®€å–ç‚ºäºŒé€²åˆ¶æ•¸æ“šä¸¦ä¿å­˜åˆ°æœƒè©±ç‹€æ…‹
                        try:
                            # è®€å–éŸ³é »æ–‡ä»¶
                            with open(audio_path, "rb") as f:
                                audio_bytes = f.read()
                                
                            # ä¿å­˜åˆ°æœƒè©±ç‹€æ…‹ï¼Œè®“ä¸»ç·šç¨‹å¯ä»¥æ’­æ”¾
                            st.session_state["audio_bytes_to_play"] = audio_bytes
                            # å¢åŠ è¨ˆæ•¸å™¨ä»¥å¼·åˆ¶é‡æ–°æ¸²æŸ“
                            st.session_state["audio_play_counter"] += 1
                            
                            print(f"å·²å°‡éŸ³é »æ•¸æ“šä¿å­˜åˆ°æœƒè©±ç‹€æ…‹ï¼Œç­‰å¾…ä¸»ç·šç¨‹æ’­æ”¾: {audio_path}")
                            
                            # å¼·åˆ¶Streamlité‡æ–°é‹è¡Œä»¥æ’­æ”¾éŸ³é »
                            # æ³¨æ„ï¼šé€™è£¡ä¸èƒ½ç›´æ¥èª¿ç”¨st.experimental_rerun()ï¼Œå› ç‚ºåœ¨ç·šç¨‹ä¸­ä¸èƒ½èª¿ç”¨Streamlitå‡½æ•¸
                        except Exception as e:
                            print(f"è™•ç†éŸ³é »æ•¸æ“šå‡ºéŒ¯: {str(e)}")
                            import traceback
                            print(traceback.format_exc())
                        
                        is_playing = False
                        print(f"éŸ³é »æ–‡ä»¶å·²æ·»åŠ åˆ°æ’­æ”¾åˆ—è¡¨ï¼Œç•¶å‰åˆ—è¡¨é•·åº¦: {len(audio_files_list)}")
                    else:
                        print("éŸ³é »æ•¸æ“šç‚ºç©ºï¼Œè·³éè™•ç†")
                    
                except Exception as e:
                    print(f"æ’­æ”¾éŸ³é »å‡ºéŒ¯: {str(e)}")
                    import traceback
                    print(traceback.format_exc())
                    is_playing = False
            else:
                # å¦‚æœéšŠåˆ—ç‚ºç©ºï¼Œç­‰å¾…ä¸€æ®µæ™‚é–“
                empty_count += 1
                
                # å¦‚æœé€£çºŒå¤šæ¬¡ç©ºéšŠåˆ—ï¼Œä¸”éŸ³é »æµå·²åœæ­¢ï¼Œå‰‡é€€å‡º
                if empty_count > max_empty_count and not is_connected_to_tts:
                    print(f"é€£çºŒ {max_empty_count} æ¬¡ç©ºéšŠåˆ—ä¸”éŸ³é »æµå·²åœæ­¢ï¼ŒçµæŸæ’­æ”¾ç·šç¨‹")
                    break
                
                time.sleep(0.1)
    except Exception as e:
        print(f"éŸ³é »æ’­æ”¾ç·šç¨‹å‡ºéŒ¯: {str(e)}")
        import traceback
        print(traceback.format_exc())
    finally:
        is_playing = False
        print("éŸ³é »æ’­æ”¾ç·šç¨‹çµæŸ")

def evaluate_pronunciation(audio_bytes: bytes, text: str) -> Optional[Dict[str, Any]]:
    """
    è©•ä¼°ç™¼éŸ³æº–ç¢ºåº¦
    
    Args:
        audio_bytes: éŸ³é »æ•¸æ“šçš„äºŒé€²åˆ¶å…§å®¹
        text: åƒè€ƒæ–‡æœ¬
        
    Returns:
        è©•ä¼°çµæœ
    """
    try:
        # æº–å‚™è«‹æ±‚æ•¸æ“š
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        payload = {
            "audio_base64": audio_base64,
            "text": text
        }
        
        # ç™¼é€è«‹æ±‚
        response = requests.post(f"{API_URL}/api/pronunciation", json=payload)
        response.raise_for_status()
        result = response.json()
        
        if result.get("success", False):
            return result
        else:
            st.error("ç™¼éŸ³è©•ä¼°å¤±æ•—")
            return None
    
    except Exception as e:
        st.error(f"ç™¼éŸ³è©•ä¼°éŒ¯èª¤: {str(e)}")
        return None

def get_available_scenarios() -> Dict[str, str]:
    """
    ç²å–å¯ç”¨çš„å°è©±æƒ…å¢ƒ
    
    Returns:
        æƒ…å¢ƒå­—å…¸ {id: description}
    """
    try:
        response = requests.get(f"{API_URL}/api/scenarios")
        response.raise_for_status()
        result = response.json()
        
        if result.get("success", False):
            return result.get("scenarios", {})
        else:
            return {"general": "General English Conversation"}
    
    except Exception as e:
        st.warning(f"ç„¡æ³•ç²å–æƒ…å¢ƒåˆ—è¡¨: {str(e)}")
        return {"general": "General English Conversation"}

def chat_message(role: str, content: str):
    """
    é¡¯ç¤ºèŠå¤©æ¶ˆæ¯
    
    Args:
        role: æ¶ˆæ¯è§’è‰² (user/assistant)
        content: æ¶ˆæ¯å…§å®¹
    """
    role_class = "user" if role == "user" else "bot"
    avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"
    
    # ä½¿ç”¨HTMLå’ŒCSSä¾†ç¾åŒ–æ¶ˆæ¯é¡¯ç¤º
    st.markdown(
        f"<div class='chat-message {role_class}'>"
        f"<div style='display: flex; align-items: flex-start;'>"
        f"<div style='font-size: 1.5em; margin-right: 10px;'>{avatar}</div>"
        f"<div>{content}</div>"
        f"</div></div>",
        unsafe_allow_html=True
    )

def display_pronunciation_feedback(result: Dict[str, Any]):
    """
    é¡¯ç¤ºç™¼éŸ³è©•ä¼°åé¥‹
    
    Args:
        result: è©•ä¼°çµæœ
    """
    similarity = result.get("similarity", 0)
    feedback = result.get("feedback", "")
    original_text = result.get("original_text", "")
    transcribed_text = result.get("transcribed_text", "")
    
    # æ ¹æ“šç›¸ä¼¼åº¦é¸æ“‡æ¨£å¼
    score_class = ""
    if similarity > 90:
        score_class = "excellent"
    elif similarity > 70:
        score_class = "good"
    elif similarity > 50:
        score_class = "fair"
    else:
        score_class = "poor"
    
    st.markdown(f"""
    <div class="feedback-box">
        <h3>Pronunciation Feedback</h3>
        <div class="pronunciation-score {score_class}">
            Score: {similarity:.1f}%
        </div>
        <p><strong>Your text:</strong> {original_text}</p>
        <p><strong>What AI heard:</strong> {transcribed_text}</p>
        <p><strong>Feedback:</strong> {feedback}</p>
    </div>
    """, unsafe_allow_html=True)
    st.experimental_rerun()

def submit_message():
    """æäº¤æ¶ˆæ¯ä¸¦ç²å–å›æ‡‰ - TTSç¾åœ¨åœ¨å¾Œç«¯è™•ç†"""
    if not st.session_state["transcript"]:
        return
        
    # åœæ­¢ä»»ä½•æ­£åœ¨é€²è¡Œçš„éŸ³é »æµ
    stop_tts_stream()
    
    # ç²å–ç”¨æˆ¶æ¶ˆæ¯
    user_message = st.session_state["transcript"]
    
    # æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯åˆ°èŠå¤©æ­·å²
    st.session_state["messages"].append({"role": "user", "content": user_message})
    
    # é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯
    chat_message("user", user_message)
    
    # æ¸…ç©ºè¼¸å…¥æ¡†
    st.session_state["transcript"] = ""
    st.session_state["audio_bytes"] = None
    st.session_state["processed_audio"] = False
    
    # ç²å–AIå›æ‡‰
    with st.spinner("AIæ€è€ƒä¸­..."):
        ai_response = chat_with_llm(user_message)
    
    # æ·»åŠ AIå›æ‡‰åˆ°èŠå¤©æ­·å²
    st.session_state["messages"].append({"role": "assistant", "content": ai_response})
    
    # é¡¯ç¤ºAIå›æ‡‰
    chat_message("assistant", ai_response)
    
    # é‡ç½®å¯¦æ™‚å›æ‡‰
    st.session_state["realtime_response"] = ""
    
    # æ·»åŠ è‡ªå‹•æ’­æ”¾å®¹å™¨ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    st.markdown('<div id="auto-play-container"></div>', unsafe_allow_html=True)
    
    # å¼·åˆ¶é‡æ–°æ¸²æŸ“é é¢ä»¥é¡¯ç¤ºæ–°çš„å°è©±
    st.experimental_rerun()

def check_pronunciation():
    """æª¢æŸ¥ç™¼éŸ³æº–ç¢ºåº¦"""
    if not st.session_state["audio_bytes"] or not st.session_state["transcript"]:
        st.warning("è«‹å…ˆéŒ„éŸ³ä¸¦ç¢ºä¿æœ‰è½‰éŒ„æ–‡æœ¬")
        return
    
    # è©•ä¼°ç™¼éŸ³
    with st.spinner("æ­£åœ¨è©•ä¼°ç™¼éŸ³..."):
        result = evaluate_pronunciation(
            st.session_state["audio_bytes"],
            st.session_state["transcript"]
        )
    
    if result:
        # é¡¯ç¤ºè©•ä¼°çµæœ
        display_pronunciation_feedback(result)
        
        # é‡ç½®éŸ³é »æ•¸æ“šï¼ˆä½†ä¿ç•™æ–‡æœ¬ä»¥ä¾¿å†æ¬¡ç·´ç¿’ï¼‰
        st.session_state["audio_bytes"] = None

def reset_conversation():
    """é‡ç½®å°è©±"""
    # åœæ­¢ä»»ä½•æ­£åœ¨é€²è¡Œçš„éŸ³é »æµ
    stop_tts_stream()
    
    # é‡ç½®æœƒè©±ç‹€æ…‹
    st.session_state["messages"] = []
    st.session_state["conversation_id"] = str(uuid.uuid4())
    st.session_state["audio_bytes"] = None
    st.session_state["transcript"] = ""
    st.session_state["realtime_response"] = ""
    
    print("å°è©±å·²é‡ç½®")

def on_scenario_change():
    """æƒ…å¢ƒè®Šæ›´æ™‚é‡ç½®å°è©±"""
    reset_conversation()

# å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„HTMLéŸ³é »æ’­æ”¾å™¨
def create_audio_player():
    """å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„HTMLéŸ³é »æ’­æ”¾å™¨"""
    # å‰µå»ºä¸€å€‹å”¯ä¸€çš„IDä¾†è­˜åˆ¥éŸ³é »å…ƒç´ 
    audio_id = f"audio-player-{int(time.time())}"
    
    # å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„JavaScriptä»£ç¢¼
    js_code = f"""
    <div id="audio-container-{audio_id}"></div>
    <script>
        // å®šç¾©ä¸€å€‹å‡½æ•¸ä¾†æª¢æŸ¥æ–°çš„éŸ³é »æ•¸æ“š
        function checkForNewAudio() {{
            fetch('/api/check-audio')
                .then(response => response.json())
                .then(data => {{
                    if (data.has_audio) {{
                        // å¦‚æœæœ‰æ–°çš„éŸ³é »ï¼Œå‰µå»ºä¸€å€‹æ–°çš„éŸ³é »å…ƒç´ ä¸¦æ’­æ”¾
                        const audioContainer = document.getElementById('audio-container-{audio_id}');
                        const audioElement = document.createElement('audio');
                        audioElement.controls = true;
                        audioElement.autoplay = true;
                        audioElement.src = data.audio_url;
                        
                        // æ¸…é™¤ä¹‹å‰çš„éŸ³é »å…ƒç´ 
                        audioContainer.innerHTML = '';
                        audioContainer.appendChild(audioElement);
                    }}
                }})
                .catch(error => console.error('Error checking for audio:', error));
        }}
        
        // æ¯ç§’æª¢æŸ¥ä¸€æ¬¡æ–°çš„éŸ³é »
        setInterval(checkForNewAudio, 1000);
    </script>
    """
    
    # ä½¿ç”¨Streamlitçš„componentsæ¨¡å¡Šå°‡JavaScriptä»£ç¢¼åµŒå…¥é é¢
    components.html(js_code, height=100)

# å‰µå»ºä¸€å€‹è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶
def serve_audio_file(file_path):
    """æä¾›éŸ³é »æ–‡ä»¶ä¸‹è¼‰"""
    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            audio_bytes = f.read()
        return audio_bytes
    return None

# è¨­ç½®éŸ³é »æ¬Šé™å’Œæ’­æ”¾æŒ‰éˆ•
def setup_audio_permissions():
    """è¨­ç½®éŸ³é »æ¬Šé™æç¤ºä¸¦é¡¯ç¤ºå•Ÿç”¨æŒ‰éˆ•"""
    # ç¢ºä¿æœƒè©±ç‹€æ…‹å·²åˆå§‹åŒ–
    if "audio_permission_granted" not in st.session_state:
        st.session_state["audio_permission_granted"] = False
    
    # å¦‚æœéŸ³é »æ¬Šé™å°šæœªæˆäºˆ
    if not st.session_state["audio_permission_granted"]:
        # ä½¿ç”¨Streamlitçš„åŸç”ŸæŒ‰éˆ•ä¾†å•Ÿç”¨éŸ³é »
        if st.button("å•Ÿç”¨éŸ³é »æ’­æ”¾", type="primary", key="enable_audio_native"):
            # ç›´æ¥è¨­ç½®æ¬Šé™ç‹€æ…‹ç‚ºå·²æˆäºˆ
            st.session_state["audio_permission_granted"] = True
            # é¡¯ç¤ºæˆåŠŸæ¶ˆæ¯
            st.success("éŸ³é »æ’­æ”¾å·²å•Ÿç”¨ï¼ä½ ç¾åœ¨å¯ä»¥è½åˆ°AIæ•™å¸«çš„è²éŸ³ã€‚")
            # ä½¿ç”¨é©ç”¨æ–¼ä½ çš„Streamlitç‰ˆæœ¬çš„é‡æ–°è¼‰å…¥æ–¹æ³•
            st.experimental_rerun()
        
        # é¡¯ç¤ºèªªæ˜
        st.info("è¦è½åˆ°AIæ•™å¸«çš„è²éŸ³ï¼Œè«‹é»æ“Šä¸Šæ–¹çš„æŒ‰éˆ•ä¾†å•Ÿç”¨éŸ³é »æ’­æ”¾ã€‚")
    else:
        # é¡¯ç¤ºæˆåŠŸæ¶ˆæ¯
        st.success("éŸ³é »æ’­æ”¾å·²å•Ÿç”¨ï¼ä½ ç¾åœ¨å¯ä»¥è½åˆ°AIæ•™å¸«çš„è²éŸ³ã€‚")
        
        # ä½¿ç”¨JavaScriptè¨­ç½®æ¬Šé™ç‹€æ…‹
        js_code = """
        <script>
            window.audioPermissionGranted = true;
            console.log('Audio permission granted via session state');
            
            // å‰µå»ºä¸€å€‹äº‹ä»¶é€šçŸ¥æ¬Šé™å·²æˆäºˆ
            if (typeof document.audioPermissionEvent === 'undefined') {
                document.audioPermissionEvent = new Event('audioPermissionGranted');
                document.dispatchEvent(document.audioPermissionEvent);
                console.log('Audio permission event dispatched');
            }
        </script>
        """
        st.markdown(js_code, unsafe_allow_html=True)

# è¨­ç½®éœæ…‹æ–‡ä»¶æœå‹™
def setup_static_file_serving():
    """è¨­ç½®éœæ…‹æ–‡ä»¶æœå‹™ï¼Œä½¿éŸ³é »æ–‡ä»¶å¯ä»¥é€šéç¶²çµ¡è¨ªå•"""
    # åœ¨HTMLä¸­åµŒå…¥ä¸€å€‹éŸ³é »æ’­æ”¾å™¨å’Œæ’­æ”¾æŒ‰éˆ•
    audio_player_html = """
    <div id="audio-player-container" style="margin-top: 10px;">
        <audio id="audio-player" controls style="width: 100%; display: none;"></audio>
        <div id="audio-controls" style="margin-top: 10px; display: none;">
            <button id="play-latest-audio" style="background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin-right: 10px;">
                <span style="font-size: 16px;">â–¶</span> Play Latest Audio
            </button>
            <span id="audio-status" style="color: #666;"></span>
        </div>
    </div>
    
    <script>
        // å‰µå»ºä¸€å€‹å…¨å±€è®Šé‡ä¾†è¨˜éŒ„æœ€æ–°çš„éŸ³é » URL
        if (!window.latestAudioUrl) {
            window.latestAudioUrl = '';
        }
        
        // å‰µå»ºä¸€å€‹å‡½æ•¸ä¾†æ’­æ”¾éŸ³é »
        window.playAudio = function(audioUrl) {
            const player = document.getElementById('audio-player');
            const controls = document.getElementById('audio-controls');
            const status = document.getElementById('audio-status');
            
            // æ›´æ–°æœ€æ–°çš„éŸ³é » URL
            window.latestAudioUrl = audioUrl;
            
            // é¡¯ç¤ºæ’­æ”¾å™¨å’Œæ§åˆ¶éˆ•
            player.style.display = 'block';
            controls.style.display = 'block';
            
            // å˜—è©¦æ’­æ”¾
            player.src = audioUrl;
            player.play().then(() => {
                console.log('Playing audio:', audioUrl);
                status.textContent = 'Playing...';
            }).catch(error => {
                console.error('Failed to play audio:', error);
                status.textContent = 'Click Play button to listen';
            });
            // æ›´æ–°ç‹€æ…‹
            status.textContent = 'New audio available';
            
            // å¦‚æœå·²ç¶“æˆæ¬Šï¼Œå˜—è©¦è‡ªå‹•æ’­æ”¾
            if (window.audioPermissionGranted) {
                player.src = audioUrl;
                player.play().then(() => {
                    console.log('Playing audio:', audioUrl);
                    status.textContent = 'Playing...';
                }).catch(error => {
                    console.error('Failed to play audio:', error);
                    status.textContent = 'Click Play button to listen';
                });
            } else {
                status.textContent = 'Enable audio above, then click Play';
            }
            
            console.log('Audio URL set:', audioUrl);
        };
        
        // ç›£è½æ’­æ”¾æŒ‰éˆ•é»æ“Šäº‹ä»¶
        document.addEventListener('DOMContentLoaded', function() {
            document.getElementById('play-latest-audio').addEventListener('click', function() {
                const player = document.getElementById('audio-player');
                const status = document.getElementById('audio-status');
                
                if (window.latestAudioUrl) {
                    player.src = window.latestAudioUrl;
                    player.play().then(() => {
                        console.log('Playing audio on button click:', window.latestAudioUrl);
                        status.textContent = 'Playing...';
                    }).catch(error => {
                        console.error('Failed to play audio on button click:', error);
                        status.textContent = 'Failed to play. Try again.';
                    });
                } else {
                    status.textContent = 'No audio available yet';
                }
            });
        });
        
        // ç›£è½éŸ³é »æ¬Šé™æˆäºˆäº‹ä»¶
        document.addEventListener('audioPermissionGranted', function() {
            const controls = document.getElementById('audio-controls');
            controls.style.display = 'block';
            window.audioPermissionGranted = true;
        });
    </script>
    """
    
    # åµŒå…¥éŸ³é »æ’­æ”¾å™¨
    st.markdown(audio_player_html, unsafe_allow_html=True)

# é¡¯ç¤ºæ‰€æœ‰å¯ç”¨çš„éŸ³é »æ–‡ä»¶
def display_available_audio_files():
    """é¡¯ç¤ºæœ€æ–°çš„éŸ³é »æ–‡ä»¶ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
    global audio_files_list
    
    # é‡æ–°æƒæéŸ³é »æ–‡ä»¶
    audio_files_list = scan_audio_files()
    
    print(f"Audio files list now has {len(audio_files_list)} items")
    
    # æ·»åŠ è‡ªå‹•æ’­æ”¾å®¹å™¨
    st.markdown('<div id="auto-play-container"></div>', unsafe_allow_html=True)
    
    # åªé¡¯ç¤ºæœ€æ–°çš„éŸ³é »æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
    if audio_files_list:
        latest_audio = audio_files_list[-1]
        audio_path = latest_audio['path']
        
        if os.path.exists(audio_path):
            try:
                file_size = os.path.getsize(audio_path)
                if file_size > 0:
                    print(f"Latest audio file: {audio_path} (size: {file_size} bytes)")
                    # ä¸éœ€è¦é¡¯ç¤ºéŸ³é »æ’­æ”¾å™¨ï¼Œå› ç‚ºæˆ‘å€‘ä½¿ç”¨è‡ªå‹•æ’­æ”¾åŠŸèƒ½
            except Exception as e:
                print(f"Error checking audio file {audio_path}: {str(e)}")

# æª¢æŸ¥ä¸¦æ’­æ”¾éŸ³é »å‡½æ•¸ - ç°¡åŒ–ç‰ˆ
def check_and_play_audio():
    """æª¢æŸ¥å…¨å±€éŸ³é »æ–‡ä»¶åˆ—è¡¨ - ç°¡åŒ–ç‰ˆæœ¬"""
    global audio_files_list
    
    # é‡æ–°æƒæéŸ³é »æ–‡ä»¶
    audio_files_list = scan_audio_files()
    
    # åªæ‰“å°æ—¥èªŒä¿¡æ¯
    if audio_files_list:
        print(f"Audio files available: {len(audio_files_list)}")
    
    return True
    # è¿”å› False è¡¨ç¤ºæ²’æœ‰éŸ³é »è¢«æ’­æ”¾
    return False

# å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„éŸ³é »æ’­æ”¾å™¨
def create_auto_refresh_audio_player():
    """å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„éŸ³é »æ’­æ”¾å™¨"""
    # å‰µå»ºä¸€å€‹å”¯ä¸€çš„IDä¾†è­˜åˆ¥éŸ³é »å…ƒç´ 
    if "audio_player_id" not in st.session_state:
        st.session_state["audio_player_id"] = f"audio-player-{int(time.time())}"
    
    # å‰µå»ºä¸€å€‹è‡ªå‹•æ›´æ–°çš„HTMLå…ƒç´ 
    audio_player_html = f"""
    <div id="audio-container-{st.session_state['audio_player_id']}"></div>
    <script>
        // å®šç¾©ä¸€å€‹å‡½æ•¸ä¾†æª¢æŸ¥æ–°çš„éŸ³é »æ–‡ä»¶
        function checkForNewAudio() {{
            // å¦‚æœæœ‰æ–°çš„éŸ³é »æ–‡ä»¶ï¼Œå°±å‰µå»ºä¸€å€‹æ–°çš„éŸ³é »å…ƒç´ ä¸¦æ’­æ”¾
            var audioContainer = document.getElementById('audio-container-{st.session_state['audio_player_id']}');
            
            // æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„éŸ³é »æ–‡ä»¶
            if (window.latestAudioUrl && window.latestAudioUrl !== window.lastPlayedAudioUrl) {{
                // å‰µå»ºä¸€å€‹æ–°çš„éŸ³é »å…ƒç´ 
                var audioElement = document.createElement('audio');
                audioElement.controls = true;
                audioElement.autoplay = true;
                audioElement.src = window.latestAudioUrl;
                
                // æ¸…é™¤ä¹‹å‰çš„éŸ³é »å…ƒç´ 
                audioContainer.innerHTML = '';
                audioContainer.appendChild(audioElement);
                
                // æ›´æ–°æœ€å¾Œæ’­æ”¾çš„éŸ³é » URL
                window.lastPlayedAudioUrl = window.latestAudioUrl;
                
                console.log('Playing new audio:', window.latestAudioUrl);
            }}
        }}
        
        // åˆå§‹åŒ–è®Šé‡
        if (!window.lastPlayedAudioUrl) {{
            window.lastPlayedAudioUrl = '';
        }}
        
        // æ¯ç§’æª¢æŸ¥ä¸€æ¬¡æ–°çš„éŸ³é »
        setInterval(checkForNewAudio, 500);
    </script>
    """
    
    # ä½¿ç”¨Streamlitçš„componentsæ¨¡å¡Šå°‡HTMLä»£ç¢¼åµŒå…¥é é¢
    components.html(audio_player_html, height=80)

# å‰µå»ºä¸€å€‹è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶
def serve_audio_files():
    """è¨­ç½®è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶"""
    # å‰µå»ºä¸€å€‹è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶
    audio_route = st.markdown("""
    <script>
    // è¨­ç½®ä¸€å€‹è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶
    if (!window.audioRoutesInitialized) {
        window.audioRoutesInitialized = true;
        
        // å‰µå»ºä¸€å€‹è‡ªå®šç¾©çš„éŸ³é »æ’­æ”¾å™¨
        const audioPlayer = document.createElement('audio');
        audioPlayer.id = 'global-audio-player';
        audioPlayer.controls = true;
        audioPlayer.style.display = 'none';
        document.body.appendChild(audioPlayer);
        
        // å‰µå»ºä¸€å€‹å…¨å±€å‡½æ•¸ä¾†æ’­æ”¾éŸ³é »
        window.playAudio = function(url) {
            console.log('Playing audio:', url);
            const player = document.getElementById('global-audio-player');
            player.src = url;
            player.play();
        };
    }
    </script>
    """, unsafe_allow_html=True)

# è¨­ç½®éœæ…‹æ–‡ä»¶æœå‹™å™¨
def setup_static_file_server():
    """è¨­ç½®éœæ…‹æ–‡ä»¶æœå‹™å™¨ä»¥æä¾›éŸ³é »æ–‡ä»¶è¨ªå•"""
    # å°‡éœæ…‹ç›®éŒ„è¨ºæ–·ä¿¡æ¯æ·»åŠ åˆ°é é¢
    st.markdown(f"""
    <div style="display: none;" id="static-file-info">
        <p>Static directory: {AUDIO_DIR}</p>
        <p>Audio files count: {len(os.listdir(AUDIO_DIR)) if os.path.exists(AUDIO_DIR) else 0}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # å‰µå»ºä¸€å€‹è·¯ç”±ä¾†æä¾›éŸ³é »æ–‡ä»¶
    # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘ä½¿ç”¨JavaScriptä¾†å‰µå»ºä¸€å€‹ç°¡å–®çš„è·¯ç”±è™•ç†ç¨‹åº
    js_code = f"""
    <script>
        // å‰µå»ºä¸€å€‹å…¨å±€è®Šé‡ä¾†è¨˜éŒ„éŸ³é »æ–‡ä»¶è·¯å¾‘
        window.audioFilePaths = {{}};  // å°‡åœ¨æ’­æ”¾æ™‚å¡«å……
        
        // å‰µå»ºä¸€å€‹å‡½æ•¸ä¾†åŠ è¼‰éŸ³é »æ–‡ä»¶
        window.loadAudioFile = function(audioPath) {{
            // å‰µå»ºä¸€å€‹æ–°çš„éŸ³é »å…ƒç´ 
            const audioElement = document.createElement('audio');
            audioElement.controls = true;
            audioElement.autoplay = true;
            audioElement.src = audioPath;
            
            // æ·»åŠ åˆ°æ–‡æª”ä¸­
            const container = document.getElementById('audio-container');
            if (container) {{
                container.innerHTML = '';
                container.appendChild(audioElement);
            }} else {{
                const newContainer = document.createElement('div');
                newContainer.id = 'audio-container';
                newContainer.style.display = 'none';
                document.body.appendChild(newContainer);
                newContainer.appendChild(audioElement);
            }}
            
            return audioElement;
        }};
        
        // å‰µå»ºä¸€å€‹å‡½æ•¸ä¾†æ’­æ”¾éŸ³é »
        window.playAudioFile = function(audioFileName) {{
            const audioPath = '/static/audio/' + audioFileName;
            const audioElement = window.loadAudioFile(audioPath);
            return audioElement;
        }};
    </script>
    """
    st.markdown(js_code, unsafe_allow_html=True)

# ä¸»ç¨‹åº
def main():
    # è¨­ç½®é é¢æ¨™é¡Œå’Œå¸ƒå±€
    st.title("è‹±èªå°è©±AIæ•™å¸« ğŸ“")
    st.markdown(get_theme_specific_css(), unsafe_allow_html=True)
    
    # ç¢ºä¿éŸ³é »ç›®éŒ„å­˜åœ¨
    ensure_audio_directory()
    
    # å‰µå»ºéŸ³é »è‡ªå‹•æ’­æ”¾å®¹å™¨
    st.markdown('<div id="auto-play-container"></div>', unsafe_allow_html=True)
    
    # å‰µå»ºéŸ³é »æ’­æ”¾å®¹å™¨
    audio_container = st.container()
    
    # æª¢æŸ¥æ˜¯å¦æœ‰éŸ³é »éœ€è¦æ’­æ”¾
    if "audio_bytes_to_play" in st.session_state and st.session_state["audio_bytes_to_play"] is not None:
        try:
            # ä½¿ç”¨Streamlitçš„åŸç”ŸéŸ³é »çµ„ä»¶æ’­æ”¾
            with audio_container:
                st.audio(st.session_state["audio_bytes_to_play"], format="audio/wav", autoplay=True)
                print(f"å·²æ’­æ”¾éŸ³é »ï¼Œè¨ˆæ•¸å™¨: {st.session_state['audio_play_counter']}")
            
            # æ’­æ”¾å¾Œæ¸…é™¤ï¼Œé¿å…é‡è¤‡æ’­æ”¾
            st.session_state["audio_bytes_to_play"] = None
        except Exception as e:
            print(f"æ’­æ”¾éŸ³é »å‡ºéŒ¯: {str(e)}")
            import traceback
            print(traceback.format_exc())
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("è¨­ç½®")
        
        # åŠŸèƒ½èªªæ˜
        st.subheader("ä½¿ç”¨æ–¹æ³•")
        st.markdown("""
        1. é»æ“Šã€Œé–‹å§‹éŒ„éŸ³ã€æŒ‰éˆ•èªªè©±
        2. éŒ„éŸ³å®Œæˆå¾Œæœƒè‡ªå‹•è½‰éŒ„ä¸¦ç™¼é€
        3. å¯ä»¥ä½¿ç”¨ã€Œæª¢æŸ¥ç™¼éŸ³ã€åŠŸèƒ½è©•ä¼°ä½ çš„ç™¼éŸ³
        4. ä½¿ç”¨ã€Œé‡ç½®å°è©±ã€é–‹å§‹æ–°çš„å°è©±
        """)
        
        st.markdown("---")
        
        # é‡ç½®æŒ‰éˆ•
        reset_key = f"reset_button_{int(time.time())}"
        if st.button("é‡ç½®å°è©±", type="primary", key=reset_key):
            reset_conversation()
    
    # å‰µå»ºå…©åˆ—å¸ƒå±€
    col1, col2 = st.columns([7, 3])
    
    # èŠå¤©å€åŸŸï¼ˆå·¦å´ï¼‰
    with col1:
        st.subheader("å°è©±å€åŸŸ")
        
        # é¡¯ç¤ºèŠå¤©æ­·å²
        chat_container = st.container()
        with chat_container:
            # é¡¯ç¤ºä¹‹å‰çš„æ¶ˆæ¯
            for message in st.session_state["messages"]:
                chat_message(message["role"], message["content"])
            
            # é¡¯ç¤ºè¼¸å…¥å€åŸŸ
            st.markdown("---")
            
            # æ–‡æœ¬è¼¸å…¥æ¡† - å¯ä»¥ç·¨è¼¯è½‰éŒ„æ–‡æœ¬
            if st.session_state["transcript"]:
                edited_text = st.text_area(
                    "ç·¨è¼¯æˆ–ç¢ºèªè½‰éŒ„æ–‡æœ¬:", 
                    value=st.session_state["transcript"],
                    height=100,
                    key="transcript_editor"
                )
                if edited_text != st.session_state["transcript"]:
                    st.session_state["transcript"] = edited_text
            
            # é¡¯ç¤ºå¯¦æ™‚å›æ‡‰ TODO make sure the real time reply work then resume this
            #if st.session_state.realtime_response:
                #st.markdown(f"<div class='realtime-response'>{st.session_state.realtime_response}</div>", unsafe_allow_html=True)
    
    # æ§åˆ¶é¢æ¿ï¼ˆå³å´ï¼‰
    with col2:
        st.subheader("æ§åˆ¶é¢æ¿")
        
        control_container = st.container()
        with control_container:
            # ä½¿ç”¨ mic_recorder çµ„ä»¶
            micro_key = f"recorder_{st.session_state.recorder_key_counter}"
            audio_data = mic_recorder(
                key=micro_key,
                start_prompt="é–‹å§‹éŒ„éŸ³",
                stop_prompt="åœæ­¢éŒ„éŸ³",
                use_container_width=True,
                format="webm"
            )
            # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„éŒ„éŸ³æ•¸æ“š
            if audio_data and audio_data['bytes'] is not None:
                # å¦‚æœå°šæœªè™•ç†
                if not st.session_state["processed_audio"]:
                    st.write("æ­£åœ¨è™•ç†éŒ„éŸ³...")
                    
                    # è¨­ç½®éŸ³é »æ¬Šé™æ¨™è¨˜ - é€™æ˜¯é—œéµæ­¥é©Ÿï¼Œå› ç‚ºç”¨æˆ¶å·²ç¶“é»æ“Šåœæ­¢éŒ„éŸ³æŒ‰éˆ•
                    st.session_state["audio_permission_granted"] = True
                    
                    # æ¿€æ´»éŸ³é »ä¸Šä¸‹æ–‡ä¸¦è¨­ç½®è‡ªå‹•æ’­æ”¾åŠŸèƒ½
                    st.markdown("""
                    <script>
                        (function() {
                            // æ’­æ”¾ä¸€å€‹éœéŸ³éŸ³é »ä¾†æ¿€æ´»éŸ³é »ä¸Šä¸‹æ–‡
                            const silentAudio = new Audio();
                            silentAudio.src = 'data:audio/mpeg;base64,SUQzBAAAAAABEVRYWFgAAAAtAAADY29tbWVudABCaWdTb3VuZEJhbmsuY29tIC8gTGFTb25vdGhlcXVlLm9yZwBURU5DAAAAHQAAA1N3aXRjaCBQbHVzIMKpIE5DSCBTb2Z0d2FyZQBUSVQyAAAABgAAAzIyMzUAVFNTRQAAAA8AAANMYXZmNTcuODMuMTAwAAAAAAAAAAAAAAD/80DEAAAAA0gAAAAATEFNRTMuMTAwVVVVVVVVVVVVVUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQsRbAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQMSkAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV';
                            silentAudio.play().catch(e => console.log('Silent audio play error (ignorable):', e));
                            
                            // è¨­ç½®å…¨å±€æ¨™è¨˜
                            window.audioPermissionGranted = true;
                            console.log('Audio permission granted from recording interaction');
                            
                            // è¨­ç½®ç›£è½å™¨ä¾†è™•ç†æ–°å¢çš„éŸ³é »å…ƒç´ 
                            const setupAutoPlayObserver = function() {
                                // ç›£è½æ–°å¢çš„éŸ³é »å…ƒç´ 
                                const observer = new MutationObserver(function(mutations) {
                                    mutations.forEach(function(mutation) {
                                        if (mutation.addedNodes) {
                                            mutation.addedNodes.forEach(function(node) {
                                                if (node.nodeName === 'AUDIO' || 
                                                   (node.nodeType === 1 && node.querySelector('audio'))) {
                                                    // ç›´æ¥å°‹æ‰¾éŸ³é »å…ƒç´ æˆ–å…¶å®¹å™¨ä¸­çš„éŸ³é »å…ƒç´ 
                                                    const audioElement = node.nodeName === 'AUDIO' ? 
                                                                       node : node.querySelector('audio');
                                                    if (audioElement) {
                                                        console.log('New audio element detected, attempting autoplay');
                                                        setTimeout(() => {
                                                            audioElement.play().catch(e => {
                                                                console.error('Autoplay failed:', e);
                                                            });
                                                        }, 500); // ç¨å¾Œå†å˜—è©¦æ’­æ”¾ï¼Œç¢ºä¿å…ƒç´ å·²å®Œå…¨åŠ è¼‰
                                                    }
                                                }
                                            });
                                        }
                                    });
                                });
                                
                                // ç›£è¦–æ•´å€‹æ–‡æª”ä»¥æ•ç²æ–°æ·»åŠ çš„éŸ³é »å…ƒç´ 
                                observer.observe(document.body, { childList: true, subtree: true });
                                console.log('Audio autoplay observer enabled');
                                return observer;
                            };
                            
                            // å•Ÿå‹•ç›£è½å™¨
                            const observer = setupAutoPlayObserver();
                            
                            // å°‡ç›£è½å™¨å­˜å„²ç‚ºå…¨å±€è®Šé‡ï¼Œä»¥é¿å…åƒåœ¾å›æ”¶
                            window.audioObserver = observer;
                        })();
                    </script>
                    """, unsafe_allow_html=True)
                    
                    st.session_state["audio_bytes"] = audio_data['bytes']
                    # æ¨™è¨˜ç‚ºå·²è™•ç†
                    st.session_state["processed_audio"] = True
                    transcript = speech_to_text(st.session_state["audio_bytes"])
                    if transcript:
                        st.session_state["transcript"] = transcript
                        st.success("è½‰éŒ„æˆåŠŸï¼")
                        # è‡ªå‹•æäº¤
                        st.session_state["recorder_key_counter"] += 1
                        submit_message()


            # æ’­æ”¾å’Œæª¢æŸ¥æŒ‰éˆ• - ä½¿ç”¨å”¯ä¸€key
            col_play, col_check = st.columns(2)
            
            with col_play:
                play_button = st.button(
                    "æ’­æ”¾éŒ„éŸ³",
                    type="secondary",
                    disabled=not st.session_state["audio_bytes"],
                    use_container_width=True,
                    key="play_button_fixed"
                )
                
                # æª¢æ¸¬æŒ‰éˆ•é»æ“Šä¸¦è¨­ç½®æ¨™è¨˜
                if play_button:
                    st.session_state["play_requested"] = True
                
                # æª¢æŸ¥æ˜¯å¦è«‹æ±‚æ’­æ”¾
                if st.session_state["play_requested"] and st.session_state["audio_bytes"]:
                    # ç›´æ¥ä½¿ç”¨Streamlitçš„audioçµ„ä»¶æ’­æ”¾
                    st.audio(st.session_state["audio_bytes"], format="audio/webm", autoplay=True)
                    st.session_state["play_requested"] = False
            
            # ç™¼éŸ³æª¢æŸ¥æŒ‰éˆ•
            with col_check:
                pron_key = f"pronunciation_button_{int(time.time())}"
                pronunciation_button = st.button(
                    "æª¢æŸ¥ç™¼éŸ³",
                    type="secondary",
                    disabled=not st.session_state["audio_bytes"] or not st.session_state["transcript"],
                    use_container_width=True,
                    key=pron_key
                )
                
                if pronunciation_button:
                    check_pronunciation()
            
            # æ‰‹å‹•é€å‡ºæŒ‰éˆ•
            submit_key = f"submit_button_{int(time.time())}"
            submit_button = st.button(
                "æ‰‹å‹•é€å‡º",
                type="primary",
                disabled=not st.session_state["transcript"],
                use_container_width=True,
                key=submit_key
            )
            
            if submit_button:
                submit_message()
            
            # é¡¯ç¤ºæƒ…å¢ƒèªªæ˜
            st.markdown("---")
            #st.markdown(f"**ç•¶å‰æƒ…å¢ƒ:** {scenario_options[st.session_state.scenario]}")
            st.markdown("èˆ‡AIè€å¸«å°è©±ï¼Œç·´ç¿’ä½ çš„è‹±èªå£èªèƒ½åŠ›ï¼")

if __name__ == "__main__":
    main()
