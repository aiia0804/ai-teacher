import os
import numpy as np
import torch
import sounddevice as sd
import soundfile as sf
import threading
import queue
import time
import re
from pathlib import Path
from typing import Optional, Union, List, Tuple, Generator, Dict, Any
from kokoro import KPipeline

class TTSManager:
    """
    æ–‡å­—è½‰èªéŸ³ç®¡ç†å™¨ï¼Œå¯¦ç¾æ™ºèƒ½ç·©è¡è™•ç†ï¼Œæä¾›æ›´æµæš¢çš„èªéŸ³è¼¸å‡ºé«”é©—ã€‚
    """
    def __init__(
        self, 
        model_dir: Optional[Union[str, Path]] = None,
        voice_file: str = "af_heart.pt",
        lang_code: str = 'a',  # 'a' è¡¨ç¤ºç¾å¼è‹±èª
        speed: float = 1.0,
        sample_rate: int = 24000,
        use_cuda: bool = True,
        min_buffer_size: int = 50,  # æœ€å°ç·©è¡å€å¤§å°ï¼ˆå­—ç¬¦æ•¸ï¼‰
        punctuation_pattern: str = r'[.!?,;:\n]',  # æ¨™é»ç¬¦è™Ÿæ¨¡å¼
        play_locally: bool = False  # æ˜¯å¦åœ¨æœ¬åœ°æ’­æ”¾éŸ³é »
        #TODO: add punctuation_pattern to handle other langue.
    ):
        """
        åˆå§‹åŒ–TTSç®¡ç†å™¨
        
        Args:
            model_dir: TTSæ¨¡å‹ç›®éŒ„ï¼Œç”¨æ–¼èªéŸ³æ–‡ä»¶
            voice_file: èªéŸ³æ–‡ä»¶å
            lang_code: èªè¨€ä»£ç¢¼
            speed: èªéŸ³é€Ÿåº¦
            sample_rate: éŸ³é »æ¡æ¨£ç‡
            use_cuda: æ˜¯å¦ä½¿ç”¨CUDA
            min_buffer_size: è§¸ç™¼TTSç”Ÿæˆçš„æœ€å°å­—ç¬¦æ•¸
            punctuation_pattern: è§¸ç™¼TTSç”Ÿæˆçš„æ¨™é»ç¬¦è™Ÿæ¨¡å¼
        """
        # åˆå§‹åŒ–æ¨¡å‹è·¯å¾‘
        if model_dir is None:
            base_dir = Path(__file__).resolve().parent.parent.parent
            self.model_dir = base_dir / "src" / "models" / "model_data" / "tts_models"
        else:
            self.model_dir = Path(model_dir)
            
        # è¨­ç½®èªéŸ³æ–‡ä»¶è·¯å¾‘ - ç°¡åŒ–è·¯å¾‘è™•ç†é‚è¼¯
        self.voice_file = voice_file
        voices_dir = self.model_dir / "voices"
        self.voice_path = voices_dir / voice_file
        if not os.path.exists(self.voice_path) and not self.voice_path.name.endswith(".pt"):
            self.voice_path = voices_dir / f"{voice_file}.pt"
        
        # è¨­ç½®å…¶ä»–åƒæ•¸
        self.lang_code = lang_code
        self.speed = speed
        self.sample_rate = sample_rate
        self.use_cuda = use_cuda and torch.cuda.is_available()
        self.play_locally = play_locally
        
        # è¨­ç½®ç·©è¡å€åƒæ•¸
        self.min_buffer_size = min_buffer_size
        self.punctuation_pattern = re.compile(punctuation_pattern)
        
        # æª¢æŸ¥èªéŸ³æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        self._check_voice_file()
        
        # åŠ è¼‰æ¨¡å‹
        self._load_model()
        
        # åˆå§‹åŒ–ç·©è¡å€å’ŒéšŠåˆ—
        self.text_buffer = ""
        self.audio_queue = queue.Queue()
        
        # åˆå§‹åŒ–ç·šç¨‹
        self.is_running = True
        self.generator_thread = threading.Thread(target=self._generator_worker, daemon=True)
        self.player_thread = threading.Thread(target=self._player_worker, daemon=True)
        
        # å•Ÿå‹•ç·šç¨‹
        self.generator_thread.start()
        self.player_thread.start()
        
        print("TTSç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ç·©è¡å€ç­–ç•¥é€²è¡Œæµæš¢èªéŸ³è¼¸å‡º")
    
    def _check_voice_file(self):
        """æª¢æŸ¥èªéŸ³æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å˜—è©¦æŸ¥æ‰¾æ›¿ä»£"""
        if not os.path.exists(self.voice_path):
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°èªéŸ³æ–‡ä»¶ {self.voice_path}")
            # æœç´¢å…¶ä»–å¯èƒ½çš„èªéŸ³æ–‡ä»¶
            voice_dir = self.model_dir / "voices"
            if not voice_dir.exists():
                voice_dir.mkdir(parents=True, exist_ok=True)
                print(f"å·²å‰µå»ºèªéŸ³ç›®éŒ„: {voice_dir}")
                
            potential_voices = list(voice_dir.glob("**/*.pt"))
            if potential_voices:
                print(f"æ‰¾åˆ°å¯èƒ½çš„èªéŸ³æ–‡ä»¶: {[p.name for p in potential_voices]}")
                # ä½¿ç”¨ç¬¬ä¸€å€‹æ‰¾åˆ°çš„èªéŸ³æ–‡ä»¶
                self.voice_path = potential_voices[0]
                print(f"å°‡ä½¿ç”¨: {self.voice_path}")
            else:
                print("æ‰¾ä¸åˆ°ä»»ä½•èªéŸ³æ–‡ä»¶ï¼ŒTTSåŠŸèƒ½å¯èƒ½ç„¡æ³•æ­£å¸¸å·¥ä½œ")
        else:
            print(f"æ‰¾åˆ°èªéŸ³æ–‡ä»¶: {self.voice_path}")
    
    def _load_model(self):
        """åŠ è¼‰KPipelineå’ŒèªéŸ³æ¨¡å‹"""
        try:
            # ç¢ºå®šè¨­å‚™
            device = "cuda" if self.use_cuda and torch.cuda.is_available() else "cpu"
            print(f"TTSä½¿ç”¨è¨­å‚™: {device}")
            
            # åˆå§‹åŒ–KPipeline
            print(f"åˆå§‹åŒ–KPipelineï¼Œlang_code={self.lang_code}")
            self.pipeline = KPipeline(lang_code=self.lang_code)
            
            # åŠ è¼‰èªéŸ³æ¨¡å‹
            if os.path.exists(self.voice_path):
                print(f"åŠ è¼‰èªéŸ³æ–‡ä»¶: {self.voice_path}")
                self.voice_tensor = torch.load(self.voice_path, weights_only=True)
                
                # æ¸¬è©¦pipelineèª¿ç”¨æ–¹å¼ï¼Œç¢ºå®šæ­£ç¢ºçš„APIèª¿ç”¨æ–¹å¼
                try:
                    # ä½¿ç”¨ç°¡çŸ­çš„æ¸¬è©¦æ–‡æœ¬
                    test_text = "Test."
                    _ = next(self.pipeline(test_text, voice=self.voice_tensor, speed=self.speed))
                    self.use_named_params = True
                    print("ä½¿ç”¨å‘½ååƒæ•¸èª¿ç”¨pipeline")
                except (TypeError, StopIteration) as e:
                    try:
                        _ = next(self.pipeline(test_text, self.voice_tensor, self.speed))
                        self.use_named_params = False
                        print("ä½¿ç”¨ä½ç½®åƒæ•¸èª¿ç”¨pipeline")
                    except Exception as e2:
                        print(f"ç„¡æ³•ç¢ºå®špipelineèª¿ç”¨æ–¹å¼: {e2}")
                        self.use_named_params = True  # é»˜èªä½¿ç”¨å‘½ååƒæ•¸
                
                print("TTSæ¨¡å‹åŠ è¼‰æˆåŠŸ!")
            else:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°èªéŸ³æ–‡ä»¶: {self.voice_path}")
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"TTSæ¨¡å‹åŠ è¼‰å¤±æ•—: {str(e)}")
    
    def _generator_worker(self):
        """
        ç”Ÿæˆç·šç¨‹ï¼šå°‡ç·©è¡å€ä¸­çš„æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³ï¼Œä¸¦å°‡èªéŸ³æ”¾å…¥æ’­æ”¾éšŠåˆ—
        """
        # å°å…¨å±€æŒä¹…åŒ–éŸ³é »ç·©è¡å€çš„å¼•ç”¨
        try:
            # å˜—è©¦å¾é‡æ§‹å¾Œçš„æ¨¡å¡Šå°å…¥
            from src.api.routes import persistent_audio_buffer
        except ImportError:
            # ä½œç‚ºå‚™é¸ï¼Œå‰µå»ºä¸€å€‹æœ¬åœ°çš„ç·©è¡å€ï¼ˆå¦‚æœç„¡æ³•å°å…¥ï¼‰
            import queue
            persistent_audio_buffer = queue.Queue(maxsize=20)
            print("è­¦å‘Šï¼šä½¿ç”¨æœ¬åœ°æŒä¹…åŒ–éŸ³é »ç·©è¡å€")
        
        while self.is_running:
            try:
                # æª¢æŸ¥ç·©è¡å€æ˜¯å¦æ‡‰è©²è™•ç†
                text_to_process = self._should_process_buffer()
                
                if text_to_process:
                    print(f"ğŸ”„ è™•ç†ç·©è¡å€æ–‡æœ¬: '{text_to_process[:30]}...'")
                    
                    # ç”ŸæˆéŸ³é »
                    audio_data = self._generate_audio_internal(text_to_process)
                    
                    if len(audio_data) > 0:
                        # å°‡éŸ³é »æ”¾å…¥æ’­æ”¾éšŠåˆ—
                        self.audio_queue.put(audio_data.copy())  # ä½¿ç”¨copyé¿å…å¼•ç”¨å•é¡Œ
                        
                        # åŒæ™‚å°‡éŸ³é »æ”¾å…¥æŒä¹…åŒ–ç·©è¡å€
                        if persistent_audio_buffer is not None:
                            try:
                                # å¦‚æœç·©è¡å€å·²æ»¿ï¼Œå…ˆç§»é™¤èˆŠçš„æ•¸æ“š
                                if persistent_audio_buffer.full():
                                    try:
                                        persistent_audio_buffer.get_nowait()
                                    except:
                                        pass
                                persistent_audio_buffer.put(audio_data.copy())
                                print(f"âœ… éŸ³é »å·²æ·»åŠ åˆ°æŒä¹…åŒ–ç·©è¡å€ï¼Œç·©è¡å€å¤§å°: {persistent_audio_buffer.qsize()}")
                            except Exception as e:
                                print(f"âŒ æ·»åŠ åˆ°æŒä¹…åŒ–ç·©è¡å€å‡ºéŒ¯: {str(e)}")
                        
                        print(f"âœ… éŸ³é »ç”Ÿæˆå®Œæˆï¼Œé•·åº¦: {len(audio_data)} æ¨£æœ¬ï¼ŒéšŠåˆ—å¤§å°: {self.audio_queue.qsize()}")
                    else:
                        print("âš ï¸ ç”Ÿæˆçš„éŸ³é »ç‚ºç©º")
                
                # çŸ­æš«ä¼‘çœ ä»¥æ¸›å°‘CPUä½¿ç”¨ç‡
                time.sleep(0.1)
                
            except Exception as e:
                print(f"âŒ éŸ³é »ç”ŸæˆéŒ¯èª¤: {str(e)}")
                import traceback
                print(traceback.format_exc())
                time.sleep(0.5)  # å‡ºéŒ¯æ™‚ç¨å¾®å»¶é•·ä¼‘çœ æ™‚é–“
    
    def _player_worker(self):
        """
        æ’­æ”¾ç·šç¨‹ï¼šå¾æ’­æ”¾éšŠåˆ—ä¸­å–å‡ºéŸ³é »ä¸¦æ’­æ”¾
        """
        if not self.play_locally:
            print("æœ¬åœ°æ’­æ”¾å·²ç¦ç”¨ï¼Œæ’­æ”¾ç·šç¨‹å°‡é€€å‡º")
            return
            
        import sounddevice as sd
        
        # è¨­ç½®æ’­æ”¾åƒæ•¸
        sd.default.samplerate = self.sample_rate
        sd.default.channels = 1
        
        print(f"éŸ³é »æ’­æ”¾ç·šç¨‹å·²å•Ÿå‹•ï¼Œé‡‡æ¨£ç‡: {self.sample_rate} Hz")
        
        # è¨­ç½®ç­‰å¾…çµæŸçš„è¨ˆæ™‚å™¨
        last_audio_time = time.time()
        wait_timeout = 3.0  # ç­‰å¾…çµæŸçš„æ™‚é–“ï¼ˆç§’ï¼‰
        
        while self.is_running:
            try:
                # å¾éšŠåˆ—ä¸­å–å‡ºéŸ³é »æ•¸æ“š
                audio_data = self.get_next_audio(timeout=0.5)  # è¨­ç½®è¼ƒçŸ­çš„é€¾æ™‚æ™‚é–“
                
                if audio_data is not None and len(audio_data) > 0:
                    # æ›´æ–°æœ€å¾Œä¸€æ¬¡æ”¶åˆ°éŸ³é »çš„æ™‚é–“
                    last_audio_time = time.time()
                    
                    # æ’­æ”¾éŸ³é »
                    print(f"æ’­æ”¾éŸ³é »: {len(audio_data)} æ¨£æœ¬, é‡‡æ¨£ç‡: {self.sample_rate}")
                    sd.play(audio_data, self.sample_rate)
                    sd.wait()  # ç­‰å¾…æ’­æ”¾å®Œæˆ
                    print("éŸ³é »æ’­æ”¾å®Œæˆ")
                    
                    # æ’­æ”¾å®Œæˆå¾Œç­‰å¾…ä¸€å°æ®µæ™‚é–“ï¼Œç¢ºä¿å¥å­ä¹‹é–“æœ‰è‡ªç„¶çš„åœé “
                    time.sleep(0.1)
                else:
                    # æª¢æŸ¥æ˜¯å¦æ‡‰è©²çµæŸæ’­æ”¾
                    current_time = time.time()
                    elapsed_since_last_audio = current_time - last_audio_time
                    
                    # å¦‚æœæ–‡æœ¬ç·©è¡å€ç‚ºç©ºä¸”å·²ç¶“è¶…éç­‰å¾…é€¾æ™‚æ™‚é–“ï¼Œå‰‡å¯èƒ½å·²ç¶“æ’­æ”¾å®Œæ‰€æœ‰éŸ³é »
                    if not self.text_buffer and elapsed_since_last_audio > wait_timeout:
                        # æª¢æŸ¥ç·©è¡å€æ˜¯å¦ç‚ºç©ºï¼Œä½†ä¸çµæŸæ’­æ”¾ç·šç¨‹
                        print(f"ç­‰å¾…éŸ³é »é€¾æ™‚ ({elapsed_since_last_audio:.1f} ç§’)ï¼Œç·©è¡å€ç‚ºç©ºï¼Œç­‰å¾…æ–°çš„æ–‡æœ¬")
                        time.sleep(0.5)  # ç­‰å¾…æ›´é•·æ™‚é–“
                    else:
                        # å¦‚æœæ²’æœ‰éŸ³é »æ•¸æ“šï¼Œç­‰å¾…ä¸€æ®µæ™‚é–“
                        time.sleep(0.1)
            
            except Exception as e:
                print(f"æ’­æ”¾éŸ³é »æ™‚å‡ºéŒ¯: {str(e)}")
                time.sleep(0.5)  # å‡ºéŒ¯æ™‚ç¨å¾®å»¶é•·ä¼‘çœ æ™‚é–“
        
        print("éŸ³é »æ’­æ”¾ç·šç¨‹çµæŸ")
    
    def _should_process_buffer(self) -> Optional[str]:
        """
        æª¢æŸ¥ç·©è¡å€æ˜¯å¦æ‡‰è©²è¢«è™•ç†
        è¿”å›æ‡‰è™•ç†çš„æ–‡æœ¬ï¼Œæˆ–Noneè¡¨ç¤ºä¸æ‡‰è™•ç†
        """
        # æª¢æŸ¥ç·©è¡å€æ˜¯å¦ç‚ºç©º
        if not self.text_buffer:
            return None
            
        # æª¢æŸ¥æ˜¯å¦æª¢æ¸¬åˆ°å¥å­çµæŸæ¨™é»
        sentence_end_marks = ['.', '!', '?', ':', ';']
        
        # 1. å¦‚æœç·©è¡å€ä¸­æœ‰å®Œæ•´å¥å­ï¼ˆä»¥æ¨™é»çµå°¾ï¼‰ï¼Œå„ªå…ˆè™•ç†å®Œæ•´å¥å­
        for mark in sentence_end_marks:
            index = self.text_buffer.rfind(mark)
            if index > 0 and len(self.text_buffer) > self.min_buffer_size: # æ‰¾åˆ°äº†å¥å­çµå°¾æ¨™é»
                # æå–åˆ°é€™å€‹æ¨™é»ç‚ºæ­¢çš„æ‰€æœ‰æ–‡æœ¬ï¼ˆåŒ…å«æ¨™é»ï¼‰
                text_to_process = self.text_buffer[:index+1].strip()
                # ä¿ç•™å‰©é¤˜æ–‡æœ¬åœ¨ç·©è¡å€ä¸­
                self.text_buffer = self.text_buffer[index+1:].strip()
                print(f"æª¢æ¸¬åˆ°å®Œæ•´å¥å­ï¼Œæå–è™•ç†: '{text_to_process}'ï¼Œä¿ç•™åœ¨ç·©è¡å€: '{self.text_buffer}'")
                return text_to_process
        
        # 2. å¦‚æœç·©è¡å€è¶…éæœ€å°å¤§å°ï¼Œä½†æ²’æœ‰å®Œæ•´å¥å­ï¼Œå‰‡éœ€è¦åˆ¤æ–·æ˜¯å¦é©åˆè™•ç†
        # if len(self.text_buffer) > self.min_buffer_size:
        #     # æŸ¥æ‰¾æœ€å¾Œä¸€å€‹ç©ºæ ¼ï¼Œä½œç‚ºå¯èƒ½çš„æ–·å¥é»
        #     last_space_index = self.text_buffer.rfind(' ')
            
        #     # å¦‚æœæ‰¾åˆ°ç©ºæ ¼ï¼Œä¸¦ä¸”æœ‰è¶³å¤ çš„å…§å®¹
        #     if last_space_index > 0 and last_space_index > self.min_buffer_size / 2:
        #         # æå–åˆ°æœ€å¾Œä¸€å€‹ç©ºæ ¼ç‚ºæ­¢çš„æ‰€æœ‰æ–‡æœ¬
        #         text_to_process = self.text_buffer[:last_space_index].strip()
        #         # ä¿ç•™å‰©é¤˜æ–‡æœ¬åœ¨ç·©è¡å€ä¸­
        #         self.text_buffer = self.text_buffer[last_space_index:].strip()
        #         print(f"ç·©è¡å€é”åˆ°é–¾å€¼ï¼Œä»¥ç©ºæ ¼ç‚ºç•Œè™•ç†: '{text_to_process}'ï¼Œä¿ç•™åœ¨ç·©è¡å€: '{self.text_buffer}'")
        #         return text_to_process
        #     else:
        #         # ç·©è¡å€å¾ˆå¤§ï¼Œä½†æ²’æœ‰æ‰¾åˆ°åˆé©çš„æ–·å¥é»ï¼Œæ­¤æ™‚éœ€è¦å…¨éƒ¨è™•ç†
        #         text_to_process = self.text_buffer.strip()
        #         self.text_buffer = ""
        #         print(f"ç·©è¡å€é”åˆ°é–¾å€¼ï¼Œç„¡åˆé©æ–·å¥é»ï¼Œè™•ç†å…¨éƒ¨: '{text_to_process}'")
        #         return text_to_process
                
        # ç·©è¡å€å°šæœªé”åˆ°è™•ç†é–¾å€¼
        return None
    
    def _filter_special_tokens(self, text: str) -> str:
        """éæ¿¾ç‰¹æ®Šæ¨™è¨˜ã€URLå’ŒMarkdownæ ¼å¼ç¬¦è™Ÿ"""
        if not text:
            return ""
            
        # éæ¿¾ç‰¹æ®Šæ¨™è¨˜
        text = re.sub(r'<[^>]+>', '', text)
        
        # éæ¿¾ URL
        text = re.sub(r'https?://\S+|www\.\S+', '', text)
        
        # éæ¿¾ Markdown æ ¼å¼ç¬¦è™Ÿ
        text = re.sub(r'\*\*|__|~~|```|\[|\]|\(|\)|#|>|\|', '', text)
        
        # éæ¿¾ emoji
        emoji_pattern = re.compile("[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F700-\U0001F77F]+", flags=re.UNICODE)
        text = emoji_pattern.sub("", text)
        
        return text
        
    def _preprocess_text(self, text: str) -> str:
        """é è™•ç†æ–‡æœ¬ï¼Œç§»é™¤ç‰¹æ®Šæ¨™è¨˜ä¸¦æ¸…ç†æ ¼å¼"""
        if not text:
            return ""
            
        # éæ¿¾ç‰¹æ®Šæ¨™è¨˜ã€URLå’ŒMarkdownæ ¼å¼
        text = self._filter_special_tokens(text)
        
        # åœ¨è™•ç†å‰ä¿å­˜åŸå§‹çš„æ–‡æœ¬ï¼Œç”¨æ–¼åµéŒ¯
        original_text = text
        
        # ä¿è­·æ‰€æœ‰æ’‡è™Ÿç›¸é—œçš„çµæ§‹ï¼Œä¸åªæ˜¯"å–®å€‹å­—æ¯+æ’‡è™Ÿ+å–®å€‹å­—æ¯"çš„å½¢å¼
        # åŒ…æ‹¬ï¼šI'm, you're, don't, can't, he'sç­‰å¤šç¨®ç¸®å¯«å½¢å¼
        protected_text = text
        # è™•ç†åƒit's, that'sé€™æ¨£çš„ç¸®å¯«
        protected_text = re.sub(r"(\w+)'(\w+)", r"\1_APOSTROPHE_\2", protected_text)
        # è™•ç†åƒI'm, I'llé€™æ¨£çš„ç¸®å¯«
        protected_text = re.sub(r"(\w+)'(\w+)", r"\1_APOSTROPHE_\2", protected_text)
        # è™•ç†åƒdon't, can'té€™æ¨£çš„ç¸®å¯«
        protected_text = re.sub(r"(\w+)'(\w+)", r"\1_APOSTROPHE_\2", protected_text)
        
        # ä¿è­·ç ´æŠ˜è™Ÿå’Œå…¶ä»–å¯èƒ½è¢«èª¤è™•ç†çš„ç¬¦è™Ÿ
        protected_text = protected_text.replace("â€“", "_ENDASH_")
        protected_text = protected_text.replace("â€”", "_EMDASH_")
        protected_text = protected_text.replace("-", "_HYPHEN_")
        
        # ä¿è­·æ¨™é»ç¬¦è™Ÿï¼Œé¿å…åœ¨æ¨™é»å‰å¾Œæ·»åŠ å¤šé¤˜ç©ºæ ¼
        for punct in [',', '.', '!', '?', ':', ';']:
            protected_text = protected_text.replace(punct, f"_PUNCT_{punct}_")
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºæ ¼ï¼ˆç”¨å–®å€‹ç©ºæ ¼æ›¿æ›æ‰€æœ‰é€£çºŒç©ºæ ¼ï¼‰
        protected_text = re.sub(r'\s+', ' ', protected_text)
        
        # æ¢å¾©æ‰€æœ‰ä¿è­·çš„æ¨™è¨˜
        # å…ˆæ¢å¾©æ¨™é»ï¼Œç¢ºä¿æ¨™é»å‰ç„¡ç©ºæ ¼
        for punct in [',', '.', '!', '?', ':', ';']:
            protected_text = protected_text.replace(f" _PUNCT_{punct}_", f"{punct}")  # ç§»é™¤æ¨™é»å‰çš„ç©ºæ ¼
            protected_text = protected_text.replace(f"_PUNCT_{punct}_", f"{punct}")   # è™•ç†å…¶ä»–æƒ…æ³
        
        # æ¢å¾©æ‰€æœ‰ç¸®å¯«è©ä¸­çš„æ’‡è™Ÿ
        result_text = protected_text.replace("_APOSTROPHE_", "'")
        
        # æ¢å¾©ç ´æŠ˜è™Ÿå’Œé€£å­—ç¬¦
        result_text = result_text.replace("_ENDASH_", "â€“")
        result_text = result_text.replace("_EMDASH_", "â€”")
        result_text = result_text.replace("_HYPHEN_", "-")
        
        # ç§»é™¤å‰å¾Œç©ºæ ¼
        result_text = result_text.strip()
        
        # å¦‚æœè™•ç†å¾Œçš„æ–‡æœ¬èˆ‡åŸå§‹æ–‡æœ¬æœ‰æ˜é¡¯å·®ç•°ï¼Œè¨˜éŒ„ä¸€ä¸‹ä»¥ä¾¿èª¿è©¦
        if result_text.replace(" ", "") != original_text.replace(" ", ""):
            print(f"æ–‡æœ¬é è™•ç†å‰: '{original_text}'")
            print(f"æ–‡æœ¬é è™•ç†å¾Œ: '{result_text}'")
        
        return result_text
    
    def _generate_audio_internal(self, text: str) -> np.ndarray:
        """
        å…§éƒ¨æ–¹æ³•ï¼šç”ŸæˆéŸ³é »æ•¸æ“š
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            
        Returns:
            éŸ³é »æ•¸æ“šæˆ–ç©ºæ•¸çµ„
        """
        if not text or not text.strip():
            print("âš ï¸ æ”¶åˆ°ç©ºæ–‡æœ¬ï¼Œè·³ééŸ³é »ç”Ÿæˆ")
            return np.array([])
            
        try:
            # é è™•ç†æ–‡æœ¬
            processed_text = self._preprocess_text(text)
            if not processed_text or not processed_text.strip():
                print("âš ï¸ é è™•ç†å¾Œæ–‡æœ¬ç‚ºç©ºï¼Œè·³ééŸ³é »ç”Ÿæˆ")
                return np.array([])
            
            # ç§»é™¤å¼·åˆ¶æ·»åŠ å¥è™Ÿçš„é‚è¼¯ï¼Œä¿ç•™æ–‡æœ¬åŸç‹€
            print(f"é–‹å§‹ç‚ºæ–‡æœ¬ç”ŸæˆéŸ³é »: '{processed_text[:50]}'{'...' if len(processed_text) > 50 else ''}")
            
            # ä½¿ç”¨KPipelineç”ŸæˆéŸ³é »
            with torch.no_grad():
                # ä½¿ç”¨åœ¨_load_modelä¸­æ¸¬è©¦ç¢ºå®šçš„èª¿ç”¨æ–¹å¼
                all_audio = []
                
                if hasattr(self, 'use_named_params') and self.use_named_params:
                    # ä½¿ç”¨å‘½ååƒæ•¸èª¿ç”¨
                    print("ä½¿ç”¨å‘½ååƒæ•¸èª¿ç”¨pipeline")
                    generator = self.pipeline(processed_text, voice=self.voice_tensor, speed=self.speed)
                else:
                    # ä½¿ç”¨ä½ç½®åƒæ•¸èª¿ç”¨
                    print("ä½¿ç”¨ä½ç½®åƒæ•¸èª¿ç”¨pipeline")
                    generator = self.pipeline(processed_text, self.voice_tensor, self.speed)
                
                # æ”¶é›†éŸ³é »
                for _, _, audio in generator:
                    all_audio.append(audio)
                
                # åˆä½µéŸ³é »
                if not all_audio:
                    print("ç”Ÿæˆçš„éŸ³é »ç‰‡æ®µç‚ºç©º")
                    return np.array([])
                    
                # åˆä½µæ‰€æœ‰éŸ³é »ç‰‡æ®µ
                audio_array = np.concatenate(all_audio)
                
                # ç¢ºä¿éŸ³é »æ•¸æ“šæœ‰æ•ˆ
                if audio_array.size == 0:
                    print("âš ï¸ ç”Ÿæˆçš„éŸ³é »æ•¸æ“šç‚ºç©º")
                    return np.array([])
                    
                print(f"âœ… éŸ³é »ç”ŸæˆæˆåŠŸï¼Œé•·åº¦: {len(audio_array)} æ¨£æœ¬")
                return audio_array
                
        except Exception as e:
            print(f"âŒ éŸ³é »ç”Ÿæˆå‡ºéŒ¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return np.array([])
            
    def clear_buffer(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç·©è¡å€å’ŒéŸ³é »éšåˆ—"""
        # æ¸…ç©ºæ–‡æœ¬ç·©è¡å€
        self.text_buffer = ""
            
        # æ¸…ç©ºéŸ³é »éšåˆ—
        try:
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()
                self.audio_queue.task_done()
        except Exception as e:
            print(f"æ¸…ç©ºéŸ³é »éšåˆ—å‡ºéŒ¯: {str(e)}")
            
        print("æ‰€æœ‰ç·©è¡å€å’Œéšåˆ—å·²æ¸…ç©º")
        
    def add_text(self, text: str) -> None:
        """
        æ·»åŠ æ–‡æœ¬åˆ°ç·©è¡å€ä¸­é€²è¡Œè™•ç†
            
        Args:
            text: è¦æ·»åŠ çš„æ–‡æœ¬
        """
        if not text:
            return
            
        # æ·»åŠ æ–‡æœ¬åˆ°ç·©è¡å€
        self.text_buffer += text
        print(f"æ·»åŠ æ–‡æœ¬åˆ°ç·©è¡å€: '{text}' (ç·©è¡å€ç•¶å‰å¤§å°: {len(self.text_buffer)} å­—ç¬¦)")
        
        # ç¢ºä¿æ–‡æœ¬çµå°¾æœ‰é©ç•¶çš„ç©ºæ ¼ï¼Œä»¥é¿å…å¥å­é€£åœ¨ä¸€èµ·
        # if not self.text_buffer.endswith((' ', '\n', '.', '!', '?', ',', ';', ':')):
        #     self.text_buffer += ' '
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¥å­çµæŸæ¨™é»
        if any(p in text for p in ['.', '!', '?']):
            print("æª¢æ¸¬åˆ°å¥å­çµæŸæ¨™è¨˜ï¼Œç«‹å³è™•ç†ç·©è¡å€")
            # å¼·åˆ¶è™•ç†ç·©è¡å€
            self.force_process()
    
    def force_process(self) -> None:
        """å¼·åˆ¶è™•ç†ç•¶å‰ç·©è¡å€ä¸­çš„æ–‡æœ¬ï¼Œä¸ç®¡ç·©è¡å€å¤§å°"""
        # å¾routeså°å…¥æŒä¹…åŒ–ç·©è¡å€
        try:
            from src.api.routes import persistent_audio_buffer
        except ImportError:
            # ä½œç‚ºå‚™é¸ï¼Œå‰µå»ºä¸€å€‹æœ¬åœ°çš„ç·©è¡å€ï¼ˆå¦‚æœç„¡æ³•å°å…¥ï¼‰
            import queue
            persistent_audio_buffer = queue.Queue(maxsize=20)
            print("è­¦å‘Šï¼šä½¿ç”¨æœ¬åœ°æŒä¹…åŒ–éŸ³é »ç·©è¡å€")
            
        if len(self.text_buffer) > 0:
            text_to_process = self.text_buffer
            self.text_buffer = ""
            
            # ç§»é™¤å¼·åˆ¶æ·»åŠ å¥è™Ÿçš„é‚è¼¯ï¼Œä¿ç•™æ–‡æœ¬åŸæ¨£
            print(f"ğŸ”„ å¼·åˆ¶è™•ç†ç·©è¡å€ä¸­çš„ {len(text_to_process)} å­—ç¬¦æ–‡æœ¬: '{text_to_process}'")
            
            # ç”ŸæˆéŸ³é »ä¸¦æ·»åŠ åˆ°éšŠåˆ—
            try:
                audio_data = self._generate_audio_internal(text_to_process)
                if len(audio_data) > 0:
                    self.audio_queue.put(audio_data.copy())  # ä½¿ç”¨copyé¿å…å¼•ç”¨å•é¡Œ
                    
                    # åŒæ™‚å°‡éŸ³é »æ”¾å…¥æŒä¹…åŒ–ç·©è¡å€
                    if persistent_audio_buffer is not None:
                        try:
                            # å¦‚æœç·©è¡å€å·²æ»¿ï¼Œå…ˆç§»é™¤èˆŠçš„æ•¸æ“š
                            if persistent_audio_buffer.full():
                                try:
                                    persistent_audio_buffer.get_nowait()
                                except:
                                    pass
                            persistent_audio_buffer.put(audio_data.copy())
                            print(f"âœ… éŸ³é »å·²æ·»åŠ åˆ°æŒä¹…åŒ–ç·©è¡å€ï¼Œç·©è¡å€å¤§å°: {persistent_audio_buffer.qsize()}")
                        except Exception as e:
                            print(f"âŒ æ·»åŠ åˆ°æŒä¹…åŒ–ç·©è¡å€å‡ºéŒ¯: {str(e)}")
                    
                    print(f"âœ… å¼·åˆ¶è™•ç†å®Œæˆï¼ŒéŸ³é »é•·åº¦: {len(audio_data)} æ¨£æœ¬ï¼ŒéšŠåˆ—å¤§å°: {self.audio_queue.qsize()}")
                else:
                    print("âš ï¸ å¼·åˆ¶è™•ç†ç”Ÿæˆçš„éŸ³é »ç‚ºç©º")
            except Exception as e:
                print(f"âŒ å¼·åˆ¶è™•ç†ç·©è¡å€æ™‚å‡ºéŒ¯: {str(e)}")
                import traceback
                print(traceback.format_exc())
    
    def save_audio(self, text: str, file_path: str) -> bool:
        """
        ç”Ÿæˆä¸¦ä¿å­˜éŸ³é »åˆ°æ–‡ä»¶
        
        Args:
            text: è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡æœ¬
            file_path: ä¿å­˜éŸ³é »çš„æ–‡ä»¶è·¯å¾‘
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        audio_data = self._generate_audio_internal(text)
        if len(audio_data) > 0:
            try:
                sf.write(file_path, audio_data, self.sample_rate)
                print(f"âœ… éŸ³é »å·²ä¿å­˜è‡³: {file_path}")
                return True
            except Exception as e:
                print(f"âŒ ä¿å­˜éŸ³é »éŒ¯èª¤: {str(e)}")
                return False
        return False
    
    def generate_audio(self, text: str) -> np.ndarray:
        """
        ç”ŸæˆéŸ³é »æ•¸æ“šä½†ä¸æ’­æ”¾æˆ–ä¿å­˜
        
        Args:
            text: è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡æœ¬
            
        Returns:
            ç”Ÿæˆçš„éŸ³é »æ•¸æ“šï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å›ç©ºæ•¸çµ„
        """
        return self._generate_audio_internal(text)
    
    def get_next_audio(self, timeout: float = 0.5) -> Optional[np.ndarray]:
        """
        å¾éŸ³é »éšŠåˆ—ä¸­å–å‡ºä¸‹ä¸€å€‹éŸ³é »æ®µ
        
        Args:
            timeout: ç­‰å¾…éŸ³é »æ•¸æ“šçš„æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            éŸ³é »æ•¸æ“šæˆ–Noneï¼ˆå¦‚æœéšŠåˆ—ç‚ºç©ºï¼‰
        """
        try:
            # å¦‚æœéšŠåˆ—ç‚ºç©ºä½†ç·©è¡å€æœ‰æ–‡æœ¬ï¼Œå‰‡å¼·åˆ¶è™•ç†ç·©è¡å€
            if self.audio_queue.empty() and self.text_buffer:
                # æª¢æŸ¥ç·©è¡å€ä¸­æ˜¯å¦æœ‰å®Œæ•´å¥å­
                has_complete_sentence = any(p in self.text_buffer for p in ['.', '!', '?'])
                
                if has_complete_sentence and len(self.text_buffer) > self.min_buffer_size:
                    print(f"éŸ³é »éšŠåˆ—ç‚ºç©ºï¼Œä½†ç·©è¡å€æœ‰ {len(self.text_buffer)} å­—ç¬¦ï¼Œå¼·åˆ¶è™•ç†")
                    self.force_process()
                    
                    # å¼·åˆ¶è™•ç†å¾Œå†æ¬¡æª¢æŸ¥éšŠåˆ—
                    if not self.audio_queue.empty():
                        return self.audio_queue.get(timeout=timeout)
                
            # å˜—è©¦å¾éšŠåˆ—ä¸­å–å‡ºéŸ³é »æ•¸æ“š
            if not self.audio_queue.empty():
                audio_data = self.audio_queue.get(timeout=timeout)
                
                # ç¢ºä¿éŸ³é »æ•¸æ“šä¸ç‚ºç©º
                if audio_data is not None and len(audio_data) > 0:
                    return audio_data
                else:
                    print("å–å‡ºçš„éŸ³é »æ•¸æ“šç‚ºç©ºï¼Œç¹¼çºŒç­‰å¾…")
                    return None
            else:
                # å¦‚æœéšŠåˆ—ç‚ºç©ºä½†æœ‰æŒçºŒçš„æ–‡æœ¬è¼¸å…¥ï¼Œå‰‡ä¸è¦å°å‡ºå¤ªå¤šæ—¥èªŒ
                if not self.text_buffer:
                    print("éŸ³é »éšŠåˆ—å·²ç©ºï¼Œç­‰å¾…æ•¸æ“š...")
                return None
                
            audio_data = self.audio_queue.get(timeout=timeout)
            self.audio_queue.task_done()
            if audio_data is not None:
                print(f"æˆåŠŸç²å–éŸ³é »ï¼Œé•·åº¦: {len(audio_data)} æ¨£æœ¬")
                return audio_data
            return None
        except queue.Empty:
            return None
    
    def wait_until_done(self) -> None:
        """ç­‰å¾…æ‰€æœ‰éšŠåˆ—ä¸­çš„é …ç›®è™•ç†å®Œæˆ"""
        # å¼·åˆ¶è™•ç†ç·©è¡å€ä¸­çš„å‰©é¤˜æ–‡æœ¬
        self.force_process()
        
        # ç­‰å¾…éŸ³é »éšŠåˆ—æ¸…ç©º
        try:
            self.audio_queue.join(timeout=5.0)  # æ·»åŠ è¶…æ™‚ä»¥é¿å…ç„¡é™ç­‰å¾…
            print("âœ… æ‰€æœ‰èªéŸ³è™•ç†ä»»å‹™å·²å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ ç­‰å¾…èªéŸ³è™•ç†å®Œæˆæ™‚å‡ºéŒ¯: {str(e)}")
            # æ¸…ç©ºéšŠåˆ—ä»¥é¿å…æ­»é–
            try:
                while not self.audio_queue.empty():
                    self.audio_queue.get_nowait()
                    self.audio_queue.task_done()
            except:
                pass
    
    def shutdown(self) -> None:
        """é—œé–‰TTSç®¡ç†å™¨"""
        print("ğŸ›‘ é—œé–‰TTSç®¡ç†å™¨...")
        self.is_running = False
        
        # ç­‰å¾…ç·šç¨‹çµæŸ
        if hasattr(self, 'generator_thread') and self.generator_thread.is_alive():
            self.generator_thread.join(timeout=2.0)
            
        if hasattr(self, 'player_thread') and self.player_thread.is_alive():
            self.player_thread.join(timeout=2.0)
            
        # åœæ­¢ä»»ä½•æ­£åœ¨æ’­æ”¾çš„éŸ³é »
        try:
            sd.stop()
        except:
            pass
            
        print("âœ… TTSç®¡ç†å™¨å·²é—œé–‰")

    def cleanup(self) -> None:
        """
        æ¸…ç†TTSç®¡ç†å™¨çš„è³‡æºï¼Œåœæ­¢ç·šç¨‹ä¸¦é‡‹æ”¾æ¨¡å‹è¨˜æ†¶é«”
        æ‡‰åœ¨æ‡‰ç”¨ç¨‹åºé—œé–‰æ™‚èª¿ç”¨
        """
        print("é–‹å§‹æ¸…ç†TTSç®¡ç†å™¨è³‡æº...")
        
        # åœæ­¢å·¥ä½œç·šç¨‹
        self.is_running = False
        if self.generator_thread and self.generator_thread.is_alive():
            print("ç­‰å¾…ç”Ÿæˆç·šç¨‹åœæ­¢...")
            # æ·»åŠ ä¸€å€‹å°æ®µæ–‡æœ¬ä»¥è§£é™¤ä»»ä½•å¯èƒ½çš„é˜»å¡
            self.add_text("cleanup")
            self.generator_thread.join(timeout=5)
            if self.generator_thread.is_alive():
                print("è­¦å‘Šï¼šç”Ÿæˆç·šç¨‹æœªèƒ½åœ¨è¶…æ™‚æ™‚é–“å…§åœæ­¢")
        
        # æ¸…ç©ºéšŠåˆ—
        try:
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()
                self.audio_queue.task_done()
        except:
            pass
        
        # æ¸…ç©ºæ–‡æœ¬ç·©è¡å€
        self.text_buffer = ""
        
        # é‡‹æ”¾æ¨¡å‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        if hasattr(self, 'pipeline') and self.pipeline is not None:
            print("é‡‹æ”¾TTSæ¨¡å‹è³‡æº...")
            try:
                # å˜—è©¦ä½¿ç”¨å¸¸è¦‹çš„æ¨¡å‹é‡‹æ”¾æ–¹æ³•
                if hasattr(self.pipeline, 'to'):
                    self.pipeline.to('cpu')
                
                # é‡‹æ”¾CUDAç·©å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # è¨­ç½®ç‚ºNoneä»¥å¹«åŠ©åƒåœ¾å›æ”¶
                self.pipeline = None
                self.voice_tensor = None
            except Exception as e:
                print(f"é‡‹æ”¾TTSæ¨¡å‹è³‡æºæ™‚å‡ºéŒ¯: {str(e)}")
        
        print("TTSç®¡ç†å™¨è³‡æºæ¸…ç†å®Œæˆ")

    def __del__(self):
        """ææ§‹å‡½æ•¸"""
        self.shutdown()


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    tts = TTSManager()
    
    print("\n=== æ¸¬è©¦1: åˆ†æ®µæ·»åŠ æ–‡æœ¬ ===")
    # æ¨¡æ“¬åˆ†æ®µæ¥æ”¶æ–‡æœ¬
    texts = [
        "Hello, I am your AI English teacher. ",
        "Today we're going to practice conversation skills. ",
        "Let's start with a simple greeting. ",
        "How would you say hello to someone you meet for the first time?"
    ]
    
    for i, text in enumerate(texts):
        print(f"æ·»åŠ ç¬¬ {i+1} æ®µæ–‡æœ¬: '{text}'")
        tts.add_text(text)
        time.sleep(0.5)  # æ¨¡æ“¬æ–‡æœ¬ç”Ÿæˆçš„æ™‚é–“é–“éš”
    
    # ç¢ºä¿æ‰€æœ‰æ–‡æœ¬éƒ½è¢«è™•ç†
    tts.wait_until_done()
    
    print("\n=== æ¸¬è©¦2: ä¿å­˜éŸ³é »æ–‡ä»¶ ===")
    test_text = "This is a test of the TTS system. The audio will be saved to a file."
    tts.save_audio(test_text, "test_tts_output.wav")
    
    # é—œé–‰TTSç®¡ç†å™¨
    tts.shutdown()