import os
import numpy as np
import torch
import sounddevice as sd
import soundfile as sf
import threading
import queue
import time
import re
from pathlib import Path
from typing import Optional, Union, List, Tuple, Generator, Dict, Any
from kokoro import KPipeline

class TTSManager:
    """
    æ–‡å­—è½‰èªéŸ³ç®¡ç†å™¨ï¼Œå¯¦ç¾æ™ºèƒ½ç·©è¡è™•ç†ï¼Œæä¾›æ›´æµæš¢çš„èªéŸ³è¼¸å‡ºé«”é©—ã€‚
    """
    def __init__(
        self, 
        model_dir: Optional[Union[str, Path]] = None,
        voice_file: str = "af_heart.pt",
        lang_code: str = 'a',  # 'a' è¡¨ç¤ºç¾å¼è‹±èª
        speed: float = 1.0,
        sample_rate: int = 24000,
        use_cuda: bool = True,
        min_buffer_size: int = 50,  # æœ€å°ç·©è¡å€å¤§å°ï¼ˆå­—ç¬¦æ•¸ï¼‰
        punctuation_pattern: str = r'[.!?]'  # æ¨™é»ç¬¦è™Ÿæ¨¡å¼
        #TODO: add punctuation_pattern to handle other langue.
    ):
        """
        åˆå§‹åŒ–TTSç®¡ç†å™¨
        
        Args:
            model_dir: TTSæ¨¡å‹ç›®éŒ„ï¼Œç”¨æ–¼èªéŸ³æ–‡ä»¶
            voice_file: èªéŸ³æ–‡ä»¶å
            lang_code: èªè¨€ä»£ç¢¼
            speed: èªéŸ³é€Ÿåº¦
            sample_rate: éŸ³é »æ¡æ¨£ç‡
            use_cuda: æ˜¯å¦ä½¿ç”¨CUDA
            min_buffer_size: è§¸ç™¼TTSç”Ÿæˆçš„æœ€å°å­—ç¬¦æ•¸
            punctuation_pattern: è§¸ç™¼TTSç”Ÿæˆçš„æ¨™é»ç¬¦è™Ÿæ¨¡å¼
        """
        # åˆå§‹åŒ–æ¨¡å‹è·¯å¾‘
        if model_dir is None:
            base_dir = Path(__file__).resolve().parent.parent.parent
            self.model_dir = base_dir / "src" / "models" / "tts_models"
        else:
            self.model_dir = Path(model_dir)
            
        # è¨­ç½®èªéŸ³æ–‡ä»¶è·¯å¾‘ - ç°¡åŒ–è·¯å¾‘è™•ç†é‚è¼¯
        self.voice_file = voice_file
        voices_dir = self.model_dir / "voices"
        self.voice_path = voices_dir / voice_file
        if not os.path.exists(self.voice_path) and not self.voice_path.name.endswith(".pt"):
            self.voice_path = voices_dir / f"{voice_file}.pt"
        
        # è¨­ç½®å…¶ä»–åƒæ•¸
        self.lang_code = lang_code
        self.speed = speed
        self.sample_rate = sample_rate
        self.use_cuda = use_cuda and torch.cuda.is_available()
        
        # è¨­ç½®ç·©è¡å€åƒæ•¸
        self.min_buffer_size = min_buffer_size
        self.punctuation_pattern = re.compile(punctuation_pattern)
        
        # æª¢æŸ¥èªéŸ³æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        self._check_voice_file()
        
        # åŠ è¼‰æ¨¡å‹
        self._load_model()
        
        # åˆå§‹åŒ–ç·©è¡å€å’ŒéšŠåˆ—
        self.text_buffer = ""
        self.audio_queue = queue.Queue()
        
        # åˆå§‹åŒ–ç·šç¨‹
        self.is_running = True
        self.generator_thread = threading.Thread(target=self._generator_worker, daemon=True)
        self.player_thread = threading.Thread(target=self._player_worker, daemon=True)
        
        # å•Ÿå‹•ç·šç¨‹
        self.generator_thread.start()
        self.player_thread.start()
        
        print("TTSç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ç·©è¡å€ç­–ç•¥é€²è¡Œæµæš¢èªéŸ³è¼¸å‡º")
    
    def _check_voice_file(self):
        """æª¢æŸ¥èªéŸ³æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å˜—è©¦æŸ¥æ‰¾æ›¿ä»£"""
        if not os.path.exists(self.voice_path):
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°èªéŸ³æ–‡ä»¶ {self.voice_path}")
            # æœç´¢å…¶ä»–å¯èƒ½çš„èªéŸ³æ–‡ä»¶
            voice_dir = self.model_dir / "voices"
            if not voice_dir.exists():
                voice_dir.mkdir(parents=True, exist_ok=True)
                print(f"å·²å‰µå»ºèªéŸ³ç›®éŒ„: {voice_dir}")
                
            potential_voices = list(voice_dir.glob("**/*.pt"))
            if potential_voices:
                print(f"æ‰¾åˆ°å¯èƒ½çš„èªéŸ³æ–‡ä»¶: {[p.name for p in potential_voices]}")
                # ä½¿ç”¨ç¬¬ä¸€å€‹æ‰¾åˆ°çš„èªéŸ³æ–‡ä»¶
                self.voice_path = potential_voices[0]
                print(f"å°‡ä½¿ç”¨: {self.voice_path}")
            else:
                print("æ‰¾ä¸åˆ°ä»»ä½•èªéŸ³æ–‡ä»¶ï¼ŒTTSåŠŸèƒ½å¯èƒ½ç„¡æ³•æ­£å¸¸å·¥ä½œ")
        else:
            print(f"æ‰¾åˆ°èªéŸ³æ–‡ä»¶: {self.voice_path}")
    
    def _load_model(self):
        """åŠ è¼‰KPipelineå’ŒèªéŸ³æ¨¡å‹"""
        try:
            # ç¢ºå®šè¨­å‚™
            device = "cuda" if self.use_cuda and torch.cuda.is_available() else "cpu"
            print(f"TTSä½¿ç”¨è¨­å‚™: {device}")
            
            # åˆå§‹åŒ–KPipeline
            print(f"åˆå§‹åŒ–KPipelineï¼Œlang_code={self.lang_code}")
            self.pipeline = KPipeline(lang_code=self.lang_code)
            
            # åŠ è¼‰èªéŸ³æ¨¡å‹
            if os.path.exists(self.voice_path):
                print(f"åŠ è¼‰èªéŸ³æ–‡ä»¶: {self.voice_path}")
                self.voice_tensor = torch.load(self.voice_path, weights_only=True)
                
                # æ¸¬è©¦pipelineèª¿ç”¨æ–¹å¼ï¼Œç¢ºå®šæ­£ç¢ºçš„APIèª¿ç”¨æ–¹å¼
                try:
                    # ä½¿ç”¨ç°¡çŸ­çš„æ¸¬è©¦æ–‡æœ¬
                    test_text = "Test."
                    _ = next(self.pipeline(test_text, voice=self.voice_tensor, speed=self.speed))
                    self.use_named_params = True
                    print("ä½¿ç”¨å‘½ååƒæ•¸èª¿ç”¨pipeline")
                except (TypeError, StopIteration) as e:
                    try:
                        _ = next(self.pipeline(test_text, self.voice_tensor, self.speed))
                        self.use_named_params = False
                        print("ä½¿ç”¨ä½ç½®åƒæ•¸èª¿ç”¨pipeline")
                    except Exception as e2:
                        print(f"ç„¡æ³•ç¢ºå®špipelineèª¿ç”¨æ–¹å¼: {e2}")
                        self.use_named_params = True  # é»˜èªä½¿ç”¨å‘½ååƒæ•¸
                
                print("TTSæ¨¡å‹åŠ è¼‰æˆåŠŸ!")
            else:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°èªéŸ³æ–‡ä»¶: {self.voice_path}")
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"TTSæ¨¡å‹åŠ è¼‰å¤±æ•—: {str(e)}")
    
    def _generator_worker(self):
        """
        ç”Ÿæˆç·šç¨‹ï¼šå°‡ç·©è¡å€ä¸­çš„æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³ï¼Œä¸¦å°‡èªéŸ³æ”¾å…¥æ’­æ”¾éšŠåˆ—
        """
        while self.is_running:
            # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„æ–‡æœ¬å¯ä»¥è™•ç†
            should_process, text_to_process = self._should_process_buffer()
            if should_process and text_to_process:
                try:
                    self.text_buffer = self.text_buffer[len(text_to_process):]       
                    print(f"â³ ç”ŸæˆèªéŸ³: '{text_to_process}'")
                    
                    # ç”ŸæˆèªéŸ³
                    start_time = time.time()
                    audio_data = self._generate_audio_internal(text_to_process)
                    
                    if len(audio_data) > 0:
                        # å°‡ç”Ÿæˆçš„éŸ³é »æ”¾å…¥æ’­æ”¾éšŠåˆ—
                        self.audio_queue.put(audio_data)
                        
                        generation_time = time.time() - start_time
                        print(f"âœ… èªéŸ³ç”Ÿæˆå®Œæˆï¼Œè€—æ™‚: {generation_time:.2f}ç§’ï¼Œæ–‡æœ¬é•·åº¦: {len(text_to_process)}å­—ç¬¦")
                    else:
                        print("âŒ æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„éŸ³é »")
                        
                except Exception as e:
                    print(f"âŒ èªéŸ³ç”ŸæˆéŒ¯èª¤: {str(e)}")
                    import traceback
                    traceback.print_exc()
            
            # çŸ­æš«ä¼‘çœ ä»¥æ¸›å°‘CPUä½¿ç”¨
            time.sleep(0.05)
    
    def _player_worker(self):
        """
        æ’­æ”¾ç·šç¨‹ï¼šå¾æ’­æ”¾éšŠåˆ—ä¸­ç²å–éŸ³é »ä¸¦æ’­æ”¾
        """
        while self.is_running:
            try:
                # å¾éšŠåˆ—ç²å–éŸ³é »æ•¸æ“šï¼ˆè¨­ç½®è¶…æ™‚ä»¥ä¾¿å¯ä»¥æª¢æŸ¥æ˜¯å¦æ‡‰è©²é€€å‡ºï¼‰
                audio_data = self.audio_queue.get(timeout=0.5)
                
                # æ’­æ”¾éŸ³é »
                print("ğŸ”Š é–‹å§‹æ’­æ”¾éŸ³é »...")
                sd.play(audio_data, samplerate=self.sample_rate)
                sd.wait()  # ç­‰å¾…æ’­æ”¾å®Œæˆ
                print("âœ… éŸ³é »æ’­æ”¾å®Œæˆ")
                
                # æ¨™è¨˜ä»»å‹™å®Œæˆ
                self.audio_queue.task_done()
                
            except queue.Empty:
                # éšŠåˆ—ç‚ºç©ºï¼Œç¹¼çºŒç­‰å¾…
                continue
            except Exception as e:
                print(f"âŒ éŸ³é »æ’­æ”¾éŒ¯èª¤: {str(e)}")
                
                # å˜—è©¦æ¸…é™¤ä»»ä½•æ­£åœ¨æ’­æ”¾çš„éŸ³é »
                try:
                    sd.stop()
                except:
                    pass
                
                # æ¨™è¨˜ä»»å‹™å®Œæˆä»¥é¿å…æ­»é–
                if 'audio_data' in locals():
                    self.audio_queue.task_done()
    
    def _should_process_buffer(self):
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²è™•ç†ç·©è¡å€ä¸­çš„æ–‡æœ¬ï¼Œä¸¦åªè¿”å›å®Œæ•´å¥å­
        """
        if not self.text_buffer or len(self.text_buffer) < self.min_buffer_size:
            return False, ""
        
        # æŸ¥æ‰¾æœ€å¾Œä¸€å€‹å¥å­çµæŸæ¨™é»çš„ä½ç½®
        matches = list(self.punctuation_pattern.finditer(self.text_buffer))
        if not matches:
            return False, ""
            
        # ç²å–æœ€å¾Œä¸€å€‹æ¨™é»ç¬¦è™Ÿçš„ä½ç½®
        last_match = matches[-1]
        end_pos = last_match.end()
        
        # åªè™•ç†åˆ°æœ€å¾Œä¸€å€‹æ¨™é»ç¬¦è™Ÿçš„æ–‡æœ¬
        return True, self.text_buffer[:end_pos]
    
    def _generate_audio_internal(self, text: str) -> np.ndarray:
        """
        å…§éƒ¨æ–¹æ³•ï¼šç”ŸæˆéŸ³é »æ•¸æ“š
        
        Args:
            text: è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡æœ¬
            
        Returns:
            ç”Ÿæˆçš„éŸ³é »æ•¸æ“šï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å›ç©ºæ•¸çµ„
        """
        if not text or text.strip() == "":
            return np.array([])
        
        try:
            # ä½¿ç”¨ç¢ºå®šçš„æ–¹å¼èª¿ç”¨pipeline
            if self.use_named_params:
                generator = self.pipeline(text, voice=self.voice_tensor, speed=self.speed)
            else:
                generator = self.pipeline(text, self.voice_tensor, self.speed)
            
            # æ”¶é›†éŸ³é »ç‰‡æ®µ
            all_audio = []
            for _, _, audio in generator:
                all_audio.append(audio)
            
            # åˆä½µéŸ³é »
            if not all_audio:
                return np.array([])
                
            full_audio = np.concatenate(all_audio)
            return full_audio
                
        except Exception as e:
            print(f"ç”ŸæˆéŸ³é »æ™‚å‡ºéŒ¯: {str(e)}")
            return np.array([])
        
    def _filter_special_tokens(self, text):
        """éæ¿¾ç‰¹æ®Šæ¨™è¨˜ã€URLå’ŒMarkdownæ ¼å¼ç¬¦è™Ÿ"""
        # éæ¿¾ç‰¹æ®Šæ¨™è¨˜
        text = re.sub(r'<[^>]+>', '', text)
        
        # éæ¿¾URL
        text = re.sub(r'https?://\S+', '', text)
        
        # éæ¿¾Markdownæ ¼å¼ç¬¦è™Ÿï¼ˆä¿ç•™æ–‡æœ¬å…§å®¹ï¼‰
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # ç§»é™¤ç²—é«”æ¨™è¨˜ **text**
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # ç§»é™¤æ–œé«”æ¨™è¨˜ *text*
        text = re.sub(r'__(.*?)__', r'\1', text)      # ç§»é™¤ä¸‹åŠƒç·šæ¨™è¨˜ __text__
        text = re.sub(r'_(.*?)_', r'\1', text)        # ç§»é™¤æ–œé«”æ¨™è¨˜ _text_
        
        # # æ¸…ç†å¤šé¤˜ç©ºæ ¼å’Œæ›è¡Œ
        # text = re.sub(r'\s+', ' ', text).strip()
        
        #éæ¿¾æ–‡æœ¬ï¼Œç§»é™¤emojiå’Œç‰¹æ®Šæ ¼å¼
        emoji_pattern = re.compile("[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F700-\U0001F77F]+", flags=re.UNICODE)
        text = emoji_pattern.sub("", text)
        return text
    
    def add_text(self, text: str) -> None:
        """
        æ·»åŠ æ–‡æœ¬åˆ°ç·©è¡å€
        
        Args:
            text: è¦æ·»åŠ çš„æ–‡æœ¬
        """
        if not text:
            return
            
        cleaned_text = self._filter_special_tokens(text)
        #cleaned_text = text
        if not cleaned_text:
            return
        # æ·»åŠ åˆ°ç·©è¡å€
        self.text_buffer += cleaned_text
        
        # å¦‚æœç·©è¡å€å·²ç¶“å¾ˆå¤§ï¼Œå¼·åˆ¶è™•ç†
        if len(self.text_buffer) > self.min_buffer_size * 3:
            print(f"âš ï¸ ç·©è¡å€å·²é”åˆ° {len(self.text_buffer)} å­—ç¬¦ï¼Œå¼·åˆ¶è™•ç†")
            temp_buffer = self.text_buffer
            self.text_buffer = ""
            
            # ç”ŸæˆéŸ³é »ä¸¦æ·»åŠ åˆ°éšŠåˆ—
            try:
                audio_data = self._generate_audio_internal(temp_buffer)
                if len(audio_data) > 0:
                    self.audio_queue.put(audio_data)
            except Exception as e:
                print(f"âŒ å¼·åˆ¶è™•ç†ç·©è¡å€æ™‚å‡ºéŒ¯: {str(e)}")
    
    def force_process(self) -> None:
        """å¼·åˆ¶è™•ç†ç•¶å‰ç·©è¡å€ä¸­çš„æ‰€æœ‰æ–‡æœ¬"""
        if not self.text_buffer:
            return
            
        print(f"ğŸ”„ å¼·åˆ¶è™•ç†ç·©è¡å€ä¸­çš„ {len(self.text_buffer)} å­—ç¬¦æ–‡æœ¬")
        temp_buffer = self.text_buffer
        self.text_buffer = ""
        
        # ç”ŸæˆéŸ³é »ä¸¦æ·»åŠ åˆ°éšŠåˆ—
        try:
            audio_data = self._generate_audio_internal(temp_buffer)
            if len(audio_data) > 0:
                self.audio_queue.put(audio_data)
        except Exception as e:
            print(f"âŒ å¼·åˆ¶è™•ç†ç·©è¡å€æ™‚å‡ºéŒ¯: {str(e)}")
    
    def save_audio(self, text: str, file_path: str) -> bool:
        """
        ç”Ÿæˆä¸¦ä¿å­˜éŸ³é »åˆ°æ–‡ä»¶
        
        Args:
            text: è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡æœ¬
            file_path: ä¿å­˜éŸ³é »çš„æ–‡ä»¶è·¯å¾‘
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        audio_data = self._generate_audio_internal(text)
        if len(audio_data) > 0:
            try:
                sf.write(file_path, audio_data, self.sample_rate)
                print(f"âœ… éŸ³é »å·²ä¿å­˜è‡³: {file_path}")
                return True
            except Exception as e:
                print(f"âŒ ä¿å­˜éŸ³é »éŒ¯èª¤: {str(e)}")
                return False
        return False
    
    def wait_until_done(self) -> None:
        """ç­‰å¾…æ‰€æœ‰éšŠåˆ—ä¸­çš„é …ç›®è™•ç†å®Œæˆ"""
        # å¼·åˆ¶è™•ç†ç·©è¡å€ä¸­çš„å‰©é¤˜æ–‡æœ¬
        self.force_process()
        
        # ç­‰å¾…éŸ³é »éšŠåˆ—æ¸…ç©º
        self.audio_queue.join()
        print("âœ… æ‰€æœ‰èªéŸ³è™•ç†ä»»å‹™å·²å®Œæˆ")
    
    def shutdown(self) -> None:
        """é—œé–‰TTSç®¡ç†å™¨"""
        print("ğŸ›‘ é—œé–‰TTSç®¡ç†å™¨...")
        self.is_running = False
        
        # ç­‰å¾…ç·šç¨‹çµæŸ
        if hasattr(self, 'generator_thread') and self.generator_thread.is_alive():
            self.generator_thread.join(timeout=2.0)
            
        if hasattr(self, 'player_thread') and self.player_thread.is_alive():
            self.player_thread.join(timeout=2.0)
            
        # åœæ­¢ä»»ä½•æ­£åœ¨æ’­æ”¾çš„éŸ³é »
        try:
            sd.stop()
        except:
            pass
            
        print("âœ… TTSç®¡ç†å™¨å·²é—œé–‰")

    def __del__(self):
        """ææ§‹å‡½æ•¸"""
        self.shutdown()


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    tts = TTSManager()
    
    print("\n=== æ¸¬è©¦1: åˆ†æ®µæ·»åŠ æ–‡æœ¬ ===")
    # æ¨¡æ“¬åˆ†æ®µæ¥æ”¶æ–‡æœ¬
    texts = [
        "Hello, I am your AI English teacher. ",
        "Today we're going to practice conversation skills. ",
        "Let's start with a simple greeting. ",
        "How would you say hello to someone you meet for the first time?"
    ]
    
    for i, text in enumerate(texts):
        print(f"æ·»åŠ ç¬¬ {i+1} æ®µæ–‡æœ¬: '{text}'")
        tts.add_text(text)
        time.sleep(0.5)  # æ¨¡æ“¬æ–‡æœ¬ç”Ÿæˆçš„æ™‚é–“é–“éš”
    
    # ç¢ºä¿æ‰€æœ‰æ–‡æœ¬éƒ½è¢«è™•ç†
    tts.wait_until_done()
    
    print("\n=== æ¸¬è©¦2: ä¿å­˜éŸ³é »æ–‡ä»¶ ===")
    test_text = "This is a test of the TTS system. The audio will be saved to a file."
    tts.save_audio(test_text, "test_tts_output.wav")
    
    # é—œé–‰TTSç®¡ç†å™¨
    tts.shutdown()